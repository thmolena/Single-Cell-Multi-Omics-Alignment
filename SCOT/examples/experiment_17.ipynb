{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be5e891-cba9-4807-8d59-2d12f562f8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c1bc0a-ea96-451e-a29d-8cb0e70d9fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d40d9fc2-6d32-4ee7-8bd4-a11084f71f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from kneed import KneeLocator\n",
    "import math\n",
    "\n",
    "import random\n",
    "\n",
    "from scot import*\n",
    "\n",
    "# For optimal transport operations:\n",
    "import ot\n",
    "\n",
    "# For pre-processing, normalization\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "import numpy as np\n",
    "import random, math, os, sys\n",
    "from sklearn.metrics import roc_auc_score, silhouette_samples\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import grad\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# For computing graph distances:\n",
    "from sklearn.neighbors import NearestNeighbors,DistanceMetric, KNeighborsClassifier, kneighbors_graph\n",
    "\n",
    "\n",
    "def model(X,y, cellTypes_X,cellTypes_y, labels, epsilon =1e-3):\n",
    "\n",
    "    def kmeans_finder(X):\n",
    "        \n",
    "        # calculate the WSS for different number of clusters\n",
    "        wss = []\n",
    "        for k in range(1, 20):\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "            kmeans.fit(X)\n",
    "            wss.append(kmeans.inertia_)\n",
    "\n",
    "        # find the elbow point using KneeLocator\n",
    "        kl = KneeLocator(range(1, 20), wss, curve='convex', direction='decreasing')\n",
    "        best_k = kl.elbow\n",
    "\n",
    "#         # plot the WSS against the number of clusters with the elbow point\n",
    "#         plt.plot(range(1, 20), wss)\n",
    "#         plt.xlabel('Number of clusters')\n",
    "#         plt.ylabel('Within-cluster sum of squares')\n",
    "#         plt.title('Elbow method for optimal number of clusters')\n",
    "#         plt.vlines(best_k, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n",
    "#         plt.show()\n",
    "\n",
    "#         print('Best number of clusters:', best_k)\n",
    "\n",
    "\n",
    "    \n",
    "        # fit the KMeans model with k clusters\n",
    "        #kmeans = KMeans(n_clusters= math.floor(X.shape[0] / best_k), random_state=42).fit(X)\n",
    "        \n",
    "        # best_k = 3\n",
    "        \n",
    "        kmeans = KMeans(n_clusters= best_k, random_state=42).fit(X)\n",
    "    \n",
    "        # get the centroids and labels\n",
    "        centroids = kmeans.cluster_centers_\n",
    "        labels = kmeans.labels_\n",
    "    \n",
    "        # loop through each centroid and find the index of the closest point\n",
    "        closest_idx = []\n",
    "        for i in range(len(centroids)):\n",
    "            distances = np.linalg.norm(X - centroids[i], axis=1)\n",
    "            closest_idx.append(np.argmin(distances))\n",
    "\n",
    "        \n",
    "#         # create a scatter plot of the data points\n",
    "#         plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')\n",
    "#         # add the cluster centroids as black crosses\n",
    "#         plt.scatter(centroids[:, 0], centroids[:, 1], marker='x', s=200, linewidths=3, color='black')\n",
    "#         # add the closest index points as red dots\n",
    "#         plt.scatter(X[closest_idx, 0], X[closest_idx, 1], marker='o', s=100, color='red')\n",
    "\n",
    "#         plt.show()\n",
    "\n",
    "        return best_k, closest_idx\n",
    "\n",
    "    \n",
    "    def calc_frac_idx(x1_mat,x2_mat):\n",
    "        \n",
    "        \"\"\"\n",
    "        Returns fraction closer than true match for each sample (as an array)\n",
    "        \"\"\"\n",
    "        \n",
    "        fracs = []\n",
    "        x = []\n",
    "        nsamp = x1_mat.shape[0]\n",
    "        rank=0\n",
    "        for row_idx in range(nsamp):\n",
    "            euc_dist = np.sqrt(np.sum(np.square(np.subtract(x1_mat[row_idx,:], x2_mat)), axis=1))\n",
    "            true_nbr = euc_dist[row_idx]\n",
    "            sort_euc_dist = sorted(euc_dist)\n",
    "            rank =sort_euc_dist.index(true_nbr)\n",
    "            frac = float(rank)/(nsamp -1)\n",
    "\n",
    "            fracs.append(frac)\n",
    "            x.append(row_idx+1)\n",
    "\n",
    "        return fracs,x\n",
    "\n",
    "    def calc_domainAveraged_FOSCTTM(x1_mat, x2_mat):\n",
    "        \n",
    "        \"\"\"\n",
    "        Outputs average FOSCTTM measure (averaged over both domains)\n",
    "        Get the fraction matched for all data points in both directions\n",
    "        Averages the fractions in both directions for each data point\n",
    "        \"\"\"\n",
    "    \n",
    "        fracs1,xs = calc_frac_idx(x1_mat, x2_mat)\n",
    "        fracs2,xs = calc_frac_idx(x2_mat, x1_mat)\n",
    "        fracs = []\n",
    "        for i in range(len(fracs1)):\n",
    "            fracs.append((fracs1[i]+fracs2[i])/2)  \n",
    "        return fracs\n",
    "\n",
    "    def calc_sil(x1_mat,x2_mat,x1_lab,x2_lab):\n",
    "        \n",
    "        \"\"\"\n",
    "        Returns silhouette score for datasets with cell clusters\n",
    "        \"\"\"\n",
    "    \n",
    "        sil = []\n",
    "        sil_d0 = []\n",
    "        sil_d3 = []\n",
    "        sil_d7 = []\n",
    "        sil_d11 = []\n",
    "        sil_npc = []\n",
    "\n",
    "        x = np.concatenate((x1_mat,x2_mat))\n",
    "        lab = np.concatenate((x1_lab,x2_lab))\n",
    "\n",
    "        sil_score = silhouette_samples(x,lab)\n",
    "\n",
    "        nsamp = x.shape[0]\n",
    "        for i in range(nsamp):\n",
    "            if(lab[i]==1):\n",
    "                sil_d0.append(sil_score[i])\n",
    "            elif(lab[i]==2):\n",
    "                sil_d3.append(sil_score[i])\n",
    "            elif(lab[i]==3):\n",
    "                sil_d7.append(sil_score[i])\n",
    "            elif(lab[i]==4):\n",
    "                sil_d11.append(sil_score[i])\n",
    "            elif(lab[i]==5):\n",
    "                sil_npc.append(sil_score[i])\n",
    "\n",
    "        avg = np.mean(sil_score)\n",
    "        d0 = sum(sil_d0)/len(sil_d0)\n",
    "        d3 = sum(sil_d3)/len(sil_d3)\n",
    "        d7 = sum(sil_d7)/len(sil_d7)\n",
    "        d11 = sum(sil_d11)/len(sil_d11)\n",
    "        npc = sum(sil_npc)/len(sil_npc)\n",
    "\n",
    "        return avg,d0,d3,d7,d11,npc\n",
    "\n",
    "    def binarize_labels(label,x):\n",
    "        \n",
    "        \"\"\"\n",
    "        Helper function for calc_auc\n",
    "        \"\"\"\n",
    "    \n",
    "        bin_lab = np.array([1] * len(x))\n",
    "        idx = np.where(x == label)\n",
    "\n",
    "        bin_lab[idx] = 0\n",
    "        return bin_lab\n",
    "\n",
    "\n",
    "    def calc_auc(x1_mat, x2_mat, x1_lab, x2_lab):\n",
    "        \n",
    "        \"\"\"\n",
    "        calculate avg. ROC AUC scores for transformed data when there are >=2 number of clusters.\n",
    "        \"\"\"\n",
    "\n",
    "        nsamp = x1_mat.shape[0]\n",
    "\n",
    "        auc = []\n",
    "        auc_d0 = []\n",
    "        auc_d3 = []\n",
    "        auc_d7 = []\n",
    "        auc_d11 = []\n",
    "        auc_npc = []\n",
    "\n",
    "        for row_idx in range(nsamp):\n",
    "   \n",
    "            euc_dist = np.sqrt(np.sum(np.square(np.subtract(x1_mat[row_idx,:], x2_mat)), axis=1))\n",
    "            y_scores = euc_dist\n",
    "            y_true = binarize_labels(x1_lab[row_idx],x2_lab)\n",
    "\n",
    "            auc_score = roc_auc_score(y_true, y_scores)\n",
    "            auc.append(auc_score)\n",
    "        \n",
    "            if(x1_lab[row_idx]==0):\n",
    "                auc_d0.append(auc_score)\n",
    "            elif(x1_lab[row_idx]==1):\n",
    "                auc_d3.append(auc_score)\n",
    "            elif(x1_lab[row_idx]==2):\n",
    "                auc_d7.append(auc_score)\n",
    "            elif(x1_lab[row_idx]==3):\n",
    "                auc_d11.append(auc_score)\n",
    "            elif(x1_lab[row_idx]==4):\n",
    "                auc_npc.append(auc_score)\n",
    "\n",
    "        avg = sum(auc)/len(auc)\n",
    "        d0 = sum(auc_d0)/len(auc_d0)\n",
    "        d3 = sum(auc_d3)/len(auc_d3)\n",
    "        d7 = sum(auc_d7)/len(auc_d7)\n",
    "        d11 = sum(auc_d11)/len(auc_d11)\n",
    "        npc = sum(auc_npc)/len(auc_npc)\n",
    "\n",
    "        return avg,d0,d3,d7,d11,npc\n",
    "\n",
    "    def transfer_accuracy(domain1, domain2, type1, type2, n):\n",
    "    \n",
    "        \"\"\"\n",
    "        Metric from UnionCom: \"Label Transfer Accuracy\"\n",
    "        \"\"\"\n",
    "    \n",
    "        knn = KNeighborsClassifier(n_neighbors=n)\n",
    "        knn.fit(domain2, type2)\n",
    "        type1_predict = knn.predict(domain1)\n",
    "        np.savetxt(\"type1_predict.txt\", type1_predict)\n",
    "        count = 0\n",
    "        for label1, label2 in zip(type1_predict, type1):\n",
    "            if label1 == label2:\n",
    "                count += 1\n",
    "        return count / len(type1)\n",
    "\n",
    "\n",
    "    def distance_matrix(X,y):\n",
    "        \n",
    "        dist = DistanceMetric.get_metric('euclidean')\n",
    "        C1 = dist.pairwise(X)\n",
    "        C2 = dist.pairwise(y)\n",
    "        return C1, C2\n",
    "\n",
    "\n",
    "    def finding_triplets(dist_matrix):\n",
    "        \n",
    "        _, closest_idx = kmeans_finder(dist_matrix)\n",
    "      \n",
    "    \n",
    "        triplets = []\n",
    "        \n",
    "        # neigh = NearestNeighbors(n_neighbors=random.randint(2, dist_matrix.shape[0]))\n",
    "        neigh = NearestNeighbors(n_neighbors=4)\n",
    "        \n",
    "        neigh.fit(dist_matrix)\n",
    "        for i in range(len(closest_idx)):\n",
    "            neigh_dist, neigh_ind = neigh.kneighbors([dist_matrix[closest_idx[i]]])\n",
    "            j = neigh_ind[0][0]\n",
    "            k = neigh_ind[0][1]\n",
    "            l = neigh_ind[0][-1]\n",
    "            triplets.append((j, k, l))\n",
    "        return triplets\n",
    "\n",
    "\n",
    "\n",
    "    def min_gromov_wasserstein_distance1(C1_fixed, C2_fixed, C1, C2, p, q, nb_iter_max=5, lr=1, epsilon = epsilon):\n",
    "    \n",
    "        loss_iter = []\n",
    "        \n",
    "        triplets_1 = finding_triplets(C1_fixed.detach().cpu().numpy())\n",
    "        \n",
    "        triplets_2 = finding_triplets(C2_fixed.detach().cpu().numpy())\n",
    "       \n",
    "        with torch.autograd.profiler.profile() as prof:\n",
    "            for i in range(nb_iter_max):\n",
    "                print('iter', i)\n",
    "\n",
    "                loss1 = ot.gromov.entropic_gromov_wasserstein2(C1, C2, p, q, loss_fun=\"square_loss\", epsilon = epsilon, tol=1e-02, verbose=True, log=False)\n",
    "                \n",
    "        \n",
    "                loss4 = ot.gromov.entropic_gromov_wasserstein2(C1_fixed, C1, p, q, loss_fun=\"square_loss\", epsilon = epsilon, tol=1e-02, verbose=True, log=False)\n",
    "\n",
    "                loss5 = ot.gromov.entropic_gromov_wasserstein2(C2_fixed, C2, p, q, loss_fun=\"square_loss\", epsilon = epsilon, tol=1e-02, verbose=True, log=False)\n",
    "        \n",
    "        \n",
    "                total_loss1 = 0\n",
    "                total_loss2 = 0\n",
    "        \n",
    "        \n",
    "            # define the triplet margin loss function\n",
    "            \n",
    "                triplet_loss_fn = nn.TripletMarginLoss(margin=1)\n",
    "            \n",
    "                for triplet in triplets_1:\n",
    "                \n",
    "                    anchor1 = C1[triplet[0]]\n",
    "                    pos1 = C1[triplet[1]] \n",
    "                    neg1 = C1[triplet[2]]\n",
    "            \n",
    "                    lossC1 = triplet_loss_fn(anchor1, pos1, neg1)\n",
    "        \n",
    "                    total_loss1 += lossC1\n",
    "            \n",
    "                triplet_loss_fn = nn.TripletMarginLoss(margin=1)\n",
    "            \n",
    "                for triplet in triplets_2:\n",
    "                \n",
    "                    anchor2 = C2[triplet[0]] \n",
    "                    pos2 = C2[triplet[1]] \n",
    "                    neg2 = C2[triplet[2]]\n",
    "        \n",
    "            \n",
    "                    lossC2 = triplet_loss_fn(anchor2, pos2, neg2)\n",
    "            \n",
    "                    total_loss2 += lossC2\n",
    "            \n",
    "            \n",
    "                loss = (loss1 + loss4+ loss5) + 1/len(triplets_1)*total_loss1 + 1/len(triplets_2)*total_loss2\n",
    "                #print(loss)\n",
    "                loss_iter.append(loss.clone().detach().cpu().numpy())\n",
    "    \n",
    "\n",
    "        # Compute the gradient of the loss with respect to the cost matrices\n",
    "                \n",
    "                loss.backward()\n",
    "                with torch.no_grad():\n",
    "                \n",
    "                    grad_C1 = C1.grad\n",
    "                \n",
    "                    grad_C2 = C2.grad\n",
    "    \n",
    "     \n",
    "                    C1 -= lr * grad_C1\n",
    "                    C2 -= lr * grad_C2\n",
    "            \n",
    "            \n",
    "                    for m in range(C1.shape[0]):\n",
    "                        C1[m][m] = 0\n",
    "             \n",
    "                    for m in range(C2.shape[0]):\n",
    "                        C2[m][m] = 0\n",
    "\n",
    "\n",
    "                    C1.grad.zero_()\n",
    "            \n",
    "                    C2.grad.zero_()\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Convert the final tensors back to numpy arrays\n",
    "        C1 = C1.detach().cpu().numpy()\n",
    "        C2 = C2.detach().cpu().numpy()\n",
    "    \n",
    "        return C1, C2, loss_iter\n",
    "    \n",
    "    X, y  = normalize(X, norm=\"l2\"), normalize(y, norm=\"l2\")\n",
    "  \n",
    "    C1, C2 = distance_matrix(X, y)\n",
    "    \n",
    "    \n",
    "    C1_torch = torch.tensor(C1, dtype=torch.float32, requires_grad=True)\n",
    "    C2_torch = torch.tensor(C2, dtype=torch.float32, requires_grad=True)\n",
    "  \n",
    "   \n",
    "    \n",
    "    p = ot.unif(C1.shape[0])\n",
    "    p = torch.tensor(p, dtype=torch.float32)\n",
    "    q = ot.unif(C2.shape[0])\n",
    "    q = torch.tensor(q, dtype=torch.float32)\n",
    "    \n",
    "    \n",
    "    C1_opt, C2_opt, loss_iter = min_gromov_wasserstein_distance1(C1_torch, C2_torch, C1_torch, C2_torch, p, q, nb_iter_max=10, lr=10,  epsilon = epsilon)\n",
    "    \n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(loss_iter)\n",
    "    plt.title(\"Loss along iterations\")\n",
    "    \n",
    "\n",
    "    p = ot.unif(C1.shape[0])\n",
    "    q = ot.unif(C2.shape[0])\n",
    "    distance_C1_opt_C2_opt = ot.gromov.entropic_gromov_wasserstein2(C1_opt, C2_opt, p, q, loss_fun = 'square_loss', epsilon=1e-2)\n",
    "    print('distance between C1_opt and C2_opt:', distance_C1_opt_C2_opt)\n",
    "\n",
    "    \n",
    "    p = ot.unif(C1.shape[0])\n",
    "    q =  ot.unif(C2.shape[0])\n",
    "    P = ot.gromov.entropic_gromov_wasserstein(C1_opt, C2_opt, p, q, loss_fun='square_loss', epsilon = epsilon, log=False, verbose=True)\n",
    " \n",
    "    # projection\n",
    "    #Projecting the first domain onto the second domain\n",
    "    y_new=y\n",
    "    weights=np.sum(P,axis = 0)\n",
    "    X_new =np.matmul(P, y) / weights[:, None]\n",
    "  \n",
    "\n",
    "    # We will use the average FOSCTTM measure implemented in evals.py for evaluation (metric used in the publication Demetci et al 2021)\n",
    "    # This measure reports the fraction of samples closer to a sample than its true match (FOSCTTM), averaged over all samples. \n",
    "    fracs= calc_domainAveraged_FOSCTTM(X_new, y_new)\n",
    "    print(\"Average FOSCTTM score for this alignment with X onto Y is: \", np.mean(fracs))\n",
    "    \n",
    "\n",
    "    \n",
    "    #Plotting sorted FOSCTTM to show the distributions of FOSCTTM across cells:\n",
    "    plt.figure()\n",
    "    legend_label=\"SCOT alignment FOSCTTM \\n average value: \"+str(np.mean(fracs)) #Put average FOSCTTM in the legend\n",
    "    plt.plot(np.arange(len(fracs)), np.sort(fracs), \"r--\", label=legend_label)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Cells\")\n",
    "    plt.ylabel(\"Sorted FOSCTTM\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Reduce the dimensionality of the aligned domains to two (2D) via PCA for the sake of visualization:\n",
    "    pca=PCA(n_components=2)\n",
    "    Xy_pca=pca.fit_transform(np.concatenate((X_new, y_new), axis=0))\n",
    "    X_pca=Xy_pca[0: X.shape[0],]\n",
    "    y_pca=Xy_pca[X.shape[0]:,]\n",
    "\n",
    "    #Plot aligned domains, samples colored by domain identity:\n",
    "    plt.figure()\n",
    "    plt.scatter(X_pca[:,0], X_pca[:,1], c=\"k\", s=15, label=\"Chromatin Accessibility\")\n",
    "    plt.scatter(y_pca[:,0], y_pca[:,1], c=\"r\", s=15, label=\"Gene Expression\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Colored based on domains\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    colormap = plt.get_cmap('rainbow', len(labels)) \n",
    "    plt.scatter(X_pca[:,0], X_pca[:,1], c=cellTypes_X, s=15, cmap=colormap)\n",
    "    plt.scatter(y_pca[:,0], y_pca[:,1], c=cellTypes_y, s=15, cmap=colormap)\n",
    "    # plt.colorbar()\n",
    "    cbar=plt.colorbar()\n",
    "\n",
    "    \n",
    "    # approximately center the colors on the colorbar when adding cell type labels\n",
    "    fraction_for_colorbar = (len(labels)-1)/(len(labels))\n",
    "    tick_locs = (np.arange(1,len(labels)+1)+fraction_for_colorbar) * fraction_for_colorbar \n",
    "    cbar.set_ticks(tick_locs)\n",
    "    cbar.set_ticklabels(labels) #cell-type labels\n",
    "    plt.title(\"Colored based on cell type identity\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    originalX_pca=pca.fit_transform(X)\n",
    "    originaly_pca=pca.fit_transform(y)\n",
    "\n",
    "    #Visualization of the global geometry\n",
    "    fig, (ax1, ax2)= plt.subplots(1,2)\n",
    "    ax1.scatter(originalX_pca[:,0], originalX_pca[:,1], c=\"k\", s=15)\n",
    "    ax1.set_title(\"Chromatin Accessibiliy Domain \\n *before* Alignment\")\n",
    "    ax2.scatter(originaly_pca[:,0], originaly_pca[:,1], c=\"r\", s=15)\n",
    "    ax2.set_title(\"Gene Expression Domain \\n *before* Alignment\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    #Visualization of the cell type clusters in original domains *before* alignment\n",
    "    fig, (ax1, ax2)= plt.subplots(1,2)\n",
    "\n",
    "    fig1= ax1.scatter(originalX_pca[:,0], originalX_pca[:,1], c=cellTypes_X, s=15, cmap=colormap)\n",
    "    ax1.set_title(\"Chromatin Accessibiliy \\n *before* Alignment\")\n",
    "\n",
    "    fig2= ax2.scatter(originaly_pca[:,0], originaly_pca[:,1],  c=cellTypes_y, s=15, cmap=colormap)\n",
    "    ax2.set_title(\"Gene Expression Domain \\n *before* Alignment\")\n",
    "\n",
    "    cbar=fig.colorbar(fig2)\n",
    "    cbar.set_ticks(tick_locs)\n",
    "    cbar.set_ticklabels(labels) #cell-type labels\n",
    "\n",
    "\n",
    "\n",
    "    return C1_opt, C2_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de4a17-425e-4552-b580-eb127762cc21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55df7090-91fb-4215-8b85-4af80347dcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator():\n",
    "    \n",
    "    # scrna=np.load(\"../../data/scrna_feat.npy\")\n",
    "    scrna=np.load(\"../data/scrna_feat.npy\")\n",
    "    \n",
    "    # Define the logarithmic transformation function\n",
    "    non_linear_trans = nn.Softplus()\n",
    "    scatac = non_linear_trans(torch.tensor(scrna)).detach().numpy()\n",
    "    print('scrna.shape: ', scrna.shape)\n",
    "    print('')\n",
    "    print('')\n",
    "    print('scatac.shape:', scatac.shape)\n",
    "    print('')\n",
    "    print('')\n",
    "    print('scrna:', scrna)\n",
    "    print('')\n",
    "    print('')\n",
    "    print('scatac:', scatac)\n",
    "    return scatac, scrna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d757fb-3870-459d-b679-617032ae9f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrna.shape:  (1047, 10)\n",
      "\n",
      "\n",
      "scatac.shape: (1047, 10)\n",
      "\n",
      "\n",
      "scrna: [[  6.6883364   -2.3696006    2.14278082 ...  -0.38985914   0.03180685\n",
      "    0.16824296]\n",
      " [ -1.64704263   3.87629104  -2.57201982 ...  -0.56939318   0.77513025\n",
      "    0.40657076]\n",
      " [ -3.22729615   4.55422489 -10.10911411 ...  -0.50277229   0.11965411\n",
      "    0.70274427]\n",
      " ...\n",
      " [ -2.60360565   3.75489872  -6.05216412 ...   0.24619445  -1.72947077\n",
      "   -3.24436   ]\n",
      " [ -0.94623495   4.54416359   2.29832621 ...   2.12374688  -1.05837995\n",
      "    0.42656378]\n",
      " [ -2.49249336   4.43299686   1.91649138 ...   1.89995418  -2.62129623\n",
      "    4.05023675]]\n",
      "\n",
      "\n",
      "scatac: [[6.68958098e+00 8.94000856e-02 2.25372105e+00 ... 5.17097267e-01\n",
      "  7.09177058e-01 7.80802708e-01]\n",
      " [1.76151488e-01 3.89680671e+00 7.36045937e-02 ... 4.48440760e-01\n",
      "  1.15400753e+00 9.16954272e-01]\n",
      " [3.88981623e-02 4.56469256e+00 4.07060243e-05 ... 4.73031236e-01\n",
      "  7.54762807e-01 1.10502057e+00]\n",
      " ...\n",
      " [7.13958207e-02 3.77803189e+00 2.35000142e-03 ... 8.23801811e-01\n",
      "  1.63290152e-01 3.82524678e-02]\n",
      " [3.28007849e-01 4.55473656e+00 2.39402431e+00 ... 2.23670293e+00\n",
      "  2.97892919e-01 9.29003275e-01]\n",
      " [7.94611535e-02 4.44480570e+00 2.05374780e+00 ... 2.03934690e+00\n",
      "  7.01868095e-02 4.06750504e+00]]\n",
      "Dimensions of input datasets are:  X=  (1047, 10)  y=  (1047, 10)\n"
     ]
    }
   ],
   "source": [
    "X, y = data_generator()\n",
    "print(\"Dimensions of input datasets are: \", \"X= \", X.shape, \" y= \", y.shape)\n",
    "\n",
    "#Plot aligned domains, samples colored by cell types:\n",
    "cellTypes_X=np.loadtxt(\"../data/SNAREseq_atac_types.txt\")\n",
    "cellTypes_y=np.loadtxt(\"../data/SNAREseq_rna_types.txt\")\n",
    "labels = [\"H1\", \"GM\", \"BJ\", \"K562\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2975c3-6a3f-400c-8a4a-a95d3ee1c0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.953489e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|5.183839e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.006393e-04|\n",
      "iter 1\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.954399e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|5.186549e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.006543e-04|\n",
      "iter 2\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.954416e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|5.186515e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.006591e-04|\n",
      "iter 3\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.954432e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|5.186480e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.006638e-04|\n",
      "iter 4\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.954449e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|5.186446e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.006685e-04|\n",
      "iter 5\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.954466e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|5.186411e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.006732e-04|\n",
      "iter 6\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.954483e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|5.186377e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.006779e-04|\n",
      "iter 7\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.954500e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|5.186342e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.006826e-04|\n",
      "iter 8\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.954516e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|5.186308e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.006873e-04|\n",
      "iter 9\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.954533e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|5.186273e-04|\n",
      "It.  |Err         \n",
      "-------------------\n",
      "    0|3.006920e-04|\n"
     ]
    }
   ],
   "source": [
    "C1_opt_model_1, C2_opt_model_1 = model(X,y, cellTypes_X,cellTypes_y, labels, 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a30bce-a663-4f37-920e-f326bd51b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ot.unif(C1_opt.shape[0])\n",
    "q =  ot.unif(C2_opt.shape[0])\n",
    "P = ot.gromov.entropic_gromov_wasserstein(C1_opt, C2_opt, p, q, loss_fun='square_loss', epsilon = 1e-2, log=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1486fb28-86d7-4e33-9e23-11779a324104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# projection\n",
    "#Projecting the first domain onto the second domain\n",
    "y_new=normalize(y)\n",
    "weights=np.sum(P,axis = 0)\n",
    "X_new =np.matmul(P, normalize(y)) / weights[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b57cf-c18c-4904-9821-0d899709bd80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
