{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad5ac3b-7d30-470b-9257-40b764babf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import metric_learn\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "\n",
    "# For optimal transport operations:\n",
    "import ot\n",
    "\n",
    "\n",
    "# For computing graph distances:\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "# For pre-processing, normalization\n",
    "from sklearn.preprocessing import StandardScaler, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb505a93-e29c-44c6-bdaf-6702dfc6c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatac=np.load(\"../data/scatac_feat.npy\") \n",
    "scrna=np.load(\"../data/scrna_feat.npy\")\n",
    "print(\"Dimensions of input datasets are: \", \"X= \", scatac.shape, \" y= \", scrna.shape)\n",
    "X1, X2  = normalize(scatac, norm=\"l2\"), normalize(scrna, norm=\"l2\")\n",
    "y1=np.loadtxt(\"../data/SNAREseq_atac_types.txt\")\n",
    "y2=np.loadtxt(\"../data/SNAREseq_rna_types.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a216987-5222-4b38-b348-c6ff4fdf7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1886fdf-404b-4d92-8989-2f155ef7e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = np.zeros((X1.shape[0],X1.shape[0]))\n",
    "for i in range(X1.shape[0]):\n",
    "    for j in range(X1.shape[0]):\n",
    "        C1[i][j] = np.linalg.norm(X1[i][:] - X1[j][:],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd642f0d-6f41-4d3f-9a3b-329153f87da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "C2 = np.zeros((X2.shape[0],X2.shape[0]))\n",
    "for i in range(X2.shape[0]):\n",
    "    for j in range(X2.shape[0]):\n",
    "        C2[i][j] = np.linalg.norm(X2[i][:] - X2[j][:],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc56de05-69df-44ab-9431-118e7abdad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_normalized_by_max = C1/C1.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07ef87e-d00e-4269-951a-0dfc0fa5229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "C2_normalized_by_max = C2/C2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c800f6d8-2ec6-44d6-bf04-ff6e7ce115b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval function\n",
    "\n",
    "import numpy as np\n",
    "import random, math, os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_auc_score, silhouette_samples\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def calc_frac_idx(x1_mat,x2_mat):\n",
    "    \"\"\"\n",
    "    Returns fraction closer than true match for each sample (as an array)\n",
    "    \"\"\"\n",
    "    fracs = []\n",
    "    x = []\n",
    "    nsamp = x1_mat.shape[0]\n",
    "    rank=0\n",
    "    for row_idx in range(nsamp):\n",
    "        euc_dist = np.sqrt(np.sum(np.square(np.subtract(x1_mat[row_idx,:], x2_mat)), axis=1))\n",
    "        true_nbr = euc_dist[row_idx]\n",
    "        sort_euc_dist = sorted(euc_dist)\n",
    "        rank =sort_euc_dist.index(true_nbr)\n",
    "        frac = float(rank)/(nsamp -1)\n",
    "\n",
    "        fracs.append(frac)\n",
    "        x.append(row_idx+1)\n",
    "\n",
    "    return fracs,x\n",
    "\n",
    "def calc_domainAveraged_FOSCTTM(x1_mat, x2_mat):\n",
    "    \"\"\"\n",
    "    Outputs average FOSCTTM measure (averaged over both domains)\n",
    "    Get the fraction matched for all data points in both directions\n",
    "    Averages the fractions in both directions for each data point\n",
    "    \"\"\"\n",
    "    \n",
    "    fracs1,xs = calc_frac_idx(x1_mat, x2_mat)\n",
    "    fracs2,xs = calc_frac_idx(x2_mat, x1_mat)\n",
    "    fracs = []\n",
    "    for i in range(len(fracs1)):\n",
    "        fracs.append((fracs1[i]+fracs2[i])/2)  \n",
    "    return fracs\n",
    "\n",
    "def calc_sil(x1_mat,x2_mat,x1_lab,x2_lab):\n",
    "    \"\"\"\n",
    "    Returns silhouette score for datasets with cell clusters\n",
    "    \"\"\"\n",
    "    sil = []\n",
    "    sil_d0 = []\n",
    "    sil_d3 = []\n",
    "    sil_d7 = []\n",
    "    sil_d11 = []\n",
    "    sil_npc = []\n",
    "\n",
    "    x = np.concatenate((x1_mat,x2_mat))\n",
    "    lab = np.concatenate((x1_lab,x2_lab))\n",
    "\n",
    "    sil_score = silhouette_samples(x,lab)\n",
    "\n",
    "    nsamp = x.shape[0]\n",
    "    for i in range(nsamp):\n",
    "        if(lab[i]==1):\n",
    "            sil_d0.append(sil_score[i])\n",
    "        elif(lab[i]==2):\n",
    "            sil_d3.append(sil_score[i])\n",
    "        elif(lab[i]==3):\n",
    "            sil_d7.append(sil_score[i])\n",
    "        elif(lab[i]==4):\n",
    "            sil_d11.append(sil_score[i])\n",
    "        elif(lab[i]==5):\n",
    "            sil_npc.append(sil_score[i])\n",
    "\n",
    "    avg = np.mean(sil_score)\n",
    "    d0 = sum(sil_d0)/len(sil_d0)\n",
    "    d3 = sum(sil_d3)/len(sil_d3)\n",
    "    d7 = sum(sil_d7)/len(sil_d7)\n",
    "    d11 = sum(sil_d11)/len(sil_d11)\n",
    "    npc = sum(sil_npc)/len(sil_npc)\n",
    "\n",
    "    return avg,d0,d3,d7,d11,npc\n",
    "\n",
    "def binarize_labels(label,x):\n",
    "    \"\"\"\n",
    "    Helper function for calc_auc\n",
    "    \"\"\"\n",
    "    bin_lab = np.array([1] * len(x))\n",
    "    idx = np.where(x == label)\n",
    "\n",
    "    bin_lab[idx] = 0\n",
    "    return bin_lab\n",
    "\n",
    "\n",
    "def calc_auc(x1_mat, x2_mat, x1_lab, x2_lab):\n",
    "    \"\"\"\n",
    "    calculate avg. ROC AUC scores for transformed data when there are >=2 number of clusters.\n",
    "    \"\"\"\n",
    "\n",
    "    nsamp = x1_mat.shape[0]\n",
    "\n",
    "    auc = []\n",
    "    auc_d0 = []\n",
    "    auc_d3 = []\n",
    "    auc_d7 = []\n",
    "    auc_d11 = []\n",
    "    auc_npc = []\n",
    "\n",
    "    for row_idx in range(nsamp):\n",
    "        euc_dist = np.sqrt(np.sum(np.square(np.subtract(x1_mat[row_idx,:], x2_mat)), axis=1))\n",
    "        y_scores = euc_dist\n",
    "        y_true = binarize_labels(x1_lab[row_idx],x2_lab)\n",
    "\n",
    "        auc_score = roc_auc_score(y_true, y_scores)\n",
    "        auc.append(auc_score)\n",
    "        \n",
    "        if(x1_lab[row_idx]==0):\n",
    "            auc_d0.append(auc_score)\n",
    "        elif(x1_lab[row_idx]==1):\n",
    "            auc_d3.append(auc_score)\n",
    "        elif(x1_lab[row_idx]==2):\n",
    "            auc_d7.append(auc_score)\n",
    "        elif(x1_lab[row_idx]==3):\n",
    "            auc_d11.append(auc_score)\n",
    "        elif(x1_lab[row_idx]==4):\n",
    "            auc_npc.append(auc_score)\n",
    "\n",
    "    avg = sum(auc)/len(auc)\n",
    "    d0 = sum(auc_d0)/len(auc_d0)\n",
    "    d3 = sum(auc_d3)/len(auc_d3)\n",
    "    d7 = sum(auc_d7)/len(auc_d7)\n",
    "    d11 = sum(auc_d11)/len(auc_d11)\n",
    "    npc = sum(auc_npc)/len(auc_npc)\n",
    "\n",
    "    return avg,d0,d3,d7,d11,npc\n",
    "\n",
    "def transfer_accuracy(domain1, domain2, type1, type2, n):\n",
    "    \"\"\"\n",
    "    Metric from UnionCom: \"Label Transfer Accuracy\"\n",
    "    \"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    knn.fit(domain2, type2)\n",
    "    type1_predict = knn.predict(domain1)\n",
    "    np.savetxt(\"type1_predict.txt\", type1_predict)\n",
    "    count = 0\n",
    "    for label1, label2 in zip(type1_predict, type1):\n",
    "        if label1 == label2:\n",
    "            count += 1\n",
    "    return count / len(type1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797dbb1-cb67-4384-a4df-d943e1d9a30b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12f34b1b-2fdf-4498-96e8-1b0a22f79dcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2200444948.py, line 88)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[25], line 88\u001b[0;36m\u001b[0m\n\u001b[0;31m    C2_torch.autograd.set_detect_anomaly(True).\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import pytorch_metric_learning.losses as loss\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def min_gromov_wasserstein_distance(C1, C2, nb_iter_max=10, lr=1e-2):\n",
    "    \n",
    "    # use pyTorch for our data\n",
    "        \n",
    " \n",
    "    p = ot.unif(C1.shape[0])\n",
    "    p_torch = torch.tensor(p)\n",
    "    q = ot.unif(C2.shape[0])\n",
    "    q_torch = torch.tensor(q)\n",
    "    C1_torch = C1\n",
    "    C2_torch = C2\n",
    "    X = C1.detach().numpy()  # convert A to numpy array\n",
    "\n",
    "    # perform k-means clustering with k=2\n",
    "    kmeans = KMeans(n_clusters=5)\n",
    "    kmeans.fit(X)\n",
    "    # get the cluster labels and convert them to a tensor\n",
    "    labels_1 = kmeans.labels_\n",
    "    labels_1 = torch.from_numpy(labels_1).type(torch.int64)\n",
    "\n",
    "    # Define model\n",
    "    \n",
    "    model_1 = nn.Linear(C1.shape[0], C1.shape[0])\n",
    "    \n",
    "    # Define loss function\n",
    "    # loss_function_1 = pytorch_metric_learning.losses.ProxyAnchorLoss(num_classes=C1.shape[0], embedding_size=C1.shape[1])\n",
    "    loss_function_1 = pytorch_metric_learning.losses.LiftedStructureLoss()\n",
    "    Y = C2.detach().numpy()  # convert A to numpy array\n",
    "\n",
    "    # perform k-means clustering with k=2\n",
    "    kmeans = KMeans(n_clusters=5)\n",
    "    kmeans.fit(Y)\n",
    "    # get the cluster labels and convert them to a tensor\n",
    "    labels_2 = kmeans.labels_\n",
    "    labels_2 = torch.from_numpy(labels_2).type(torch.int64)\n",
    "\n",
    "    # Define model\n",
    "    model_2 = nn.Linear(C2.shape[0], C2.shape[0])\n",
    "    \n",
    "    # Define loss function\n",
    "    # loss_function_2 = pytorch_metric_learning.losses.ProxyAnchorLoss(num_classes=C2.shape[0], embedding_size=C2.shape[1])\n",
    "    loss_function_2 = pytorch_metric_learning.losses.LiftedStructureLoss()\n",
    "    \n",
    "    loss_iter = []\n",
    "    \n",
    "    optimizer = optim.SGD([\n",
    "    {'params': model_1.parameters()},\n",
    "    {'params': model_2.parameters()},\n",
    "    {'params': loss_function_1.parameters()},\n",
    "    {'params': loss_function_2.parameters()}], lr=0.01)\n",
    "\n",
    "    for i in range(nb_iter_max):\n",
    "         \n",
    "        loss_1 = ot.gromov_wasserstein2(C1_torch,C2_torch,p_torch,q_torch)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Define optimizer\n",
    "        \n",
    "        embeddings_1 = model_1(C1)\n",
    "    \n",
    "        \n",
    "    \n",
    "        loss_2 = loss_function_1(embeddings_1, labels_1)\n",
    "        \n",
    "    \n",
    "        \n",
    "        difference_1  = model_1.weight[:C1_torch.shape[0]].detach()\n",
    "        # C1_torch  -= difference_1\n",
    "        # C1_torch.requires_grad_(True)\n",
    "        \n",
    "        embeddings_2 = model_2(C2_torch)\n",
    "    \n",
    "        \n",
    "    \n",
    "        loss_3 = loss_function_2(embeddings_2, labels_2)\n",
    "        \n",
    "    \n",
    "        \n",
    "        difference_2 = model_2.weight[:C2_torch.shape[0]].detach()\n",
    "        C2_torch -= difference_2\n",
    "        C2_torch.autograd.set_detect_anomaly(True).\n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "        loss = 0*loss_1 + 0*loss_2 + 1*loss_3\n",
    "        loss_iter.append(loss.clone().detach().cpu().numpy())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        #performs a step of projected gradient descent\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             grad1 = C1_torch.grad\n",
    "            \n",
    "#             C1_torch -= grad1 * lr\n",
    "#             C1_torch.grad.zero_()\n",
    "#             C1_torch.data = ot.utils.proj_simplex(C1_torch)\n",
    "            \n",
    "            \n",
    "#             grad2 = C2_torch.grad             \n",
    "#             C2_torch -= grad2 * lr\n",
    "#             C2_torch.grad.zero_()\n",
    "#             C2_torch.data = ot.utils.proj_simplex(C2_torch)\n",
    "            \n",
    "\n",
    "    \n",
    "    C1 = C1_torch.clone().detach().cpu().numpy()\n",
    "    C2 = C2_torch.clone().detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    return C1, C2, loss_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02825ec-603d-4346-a13e-4b5b39927112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ot\n",
    "import pytorch_metric_learning\n",
    "import matplotlib.pylab as pl\n",
    "\n",
    "C1 = torch.randn(100,100)\n",
    "C2 = torch.randn(100,100)\n",
    "\n",
    "# C1 = C1_normalized_by_max\n",
    "# C1 = torch.tensor(C1).requires_grad_(True)\n",
    "# C1 = C1.to(torch.float32)\n",
    "\n",
    "# C2 = C2_normalized_by_max\n",
    "# C2 = torch.tensor(C2).requires_grad_(True)\n",
    "# C2 = C2.to(torch.float32)\n",
    "\n",
    "C1_opt, C2_opt, loss_iter = min_gromov_wasserstein_distance(C1, C2, nb_iter_max=10, lr=1e-2)\n",
    "\n",
    "pl.figure(2)\n",
    "pl.plot(loss_iter)\n",
    "pl.title(\"Loss along iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ac82d-d4ee-4079-b380-b2b34e9c85f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a44232-dfbf-4458-b859-81dbf4a52f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa97e7c-a601-49fb-ace8-7f643e1071cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = ot.gromov_wasserstein(C1_opt, C2_opt, ot.unif(C1_opt.shape[0]), ot.unif(C2_opt.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4038d7-fed1-498d-b7cf-f95d612fc0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# projection\n",
    "\n",
    "#Projecting the first domain onto the second domain\n",
    "C1 = C1.detach().numpy()\n",
    "C2 = C2.detach().numpy()\n",
    "\n",
    "y_aligned_from_normalized=C2\n",
    "weights_from_normalized=np.sum(T,axis = 0)\n",
    "X_aligned_from_normalized=np.matmul(T, C2) / weights_from_normalized[:, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8241d6-e42b-4a7d-9545-8a9f6a33e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the average FOSCTTM measure implemented in evals.py for evaluation (metric used in the publication Demetci et al 2021)\n",
    "# This measure reports the fraction of samples closer to a sample than its true match (FOSCTTM), averaged over all samples. \n",
    "fracs=calc_domainAveraged_FOSCTTM(X_aligned_from_normalized, y_aligned_from_normalized)\n",
    "print(\"Average FOSCTTM score for this alignment with X onto Y is: \", np.mean(fracs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0877535e-84d7-47ff-ae66-8e54a5b7282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting sorted FOSCTTM to show the distributions of FOSCTTM across cells:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "legend_label=\"SCOT alignment FOSCTTM \\n average value: \"+str(np.mean(fracs)) #Put average FOSCTTM in the legend\n",
    "plt.plot(np.arange(len(fracs)), np.sort(fracs), \"r--\", label=legend_label)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Cells\")\n",
    "plt.ylabel(\"Sorted FOSCTTM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae492cda-e4d6-4daa-9dd9-727dfd15f432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb146e12-fe8e-4b47-ae00-5ab97afe8c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f301b6-ca48-4266-94d5-f5fda5154b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46f16dc-5ec8-4754-82a1-e00bfd610f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def min_gromov_wasserstein_distance(C1, C2, nb_iter_max=10, lr=1e-2):\n",
    "    \n",
    "    # use pyTorch for our data\n",
    "        \n",
    "    C1_torch = torch.tensor(C1).requires_grad_(True)\n",
    "    C2_torch = torch.tensor(C2).requires_grad_(True)\n",
    "    p = ot.unif(C1_torch.shape[0])\n",
    "    p_torch = torch.tensor(p)\n",
    "    q = ot.unif(C2_torch.shape[0])\n",
    "    q_torch = torch.tensor(q)\n",
    "    \n",
    "    loss_iter = []\n",
    "    \n",
    "    for i in range(nb_iter_max):\n",
    "        loss = ot.gromov_wasserstein2(C1_torch,C2_torch,p_torch,q_torch)\n",
    "        \n",
    "        \n",
    "        loss_iter.append(loss.clone().detach().cpu().numpy())\n",
    "        loss.backward()\n",
    "        \n",
    "        #performs a step of projected gradient descent\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            grad1 = C1_torch.grad\n",
    "            \n",
    "            C1_torch -= grad1 * lr\n",
    "            C1_torch.grad.zero_()\n",
    "            C1_torch.data = ot.utils.proj_simplex(C1_torch)\n",
    "            \n",
    "            \n",
    "            grad2 = C2_torch.grad             \n",
    "            C2_torch -= grad2 * lr\n",
    "            C2_torch.grad.zero_()\n",
    "            C2_torch.data = ot.utils.proj_simplex(C2_torch)\n",
    "            \n",
    "\n",
    "    \n",
    "    C1 = C1_torch.clone().detach().cpu().numpy()\n",
    "    C2 = C2_torch.clone().detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    return C1, C2, loss_iter\n",
    "\n",
    "import ot\n",
    "import matplotlib.pylab as pl\n",
    "C1 = torch.randn(5,5)\n",
    "C2 = torch.randn(5,5)\n",
    "C1_opt, C2_opt, loss_iter = min_gromov_wasserstein_distance(C1, C2, nb_iter_max=1000, lr=1e-2)\n",
    "\n",
    "pl.figure(2)\n",
    "pl.plot(loss_iter)\n",
    "pl.title(\"Loss along iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4485fc24-cc9e-47d6-8fe0-b1f20a3b051a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6965046-882e-4a15-91f3-a09151ce1356",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = ot.gromov_wasserstein(C1_opt, C2_opt, ot.unif(C1_opt.shape[0]), ot.unif(C2_opt.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b9a856-56dd-462a-904b-0a44e0015f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d6a56-c6cf-434d-af2a-8dd7aef7b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# projection\n",
    "\n",
    "#Projecting the first domain onto the second domain\n",
    "y_aligned_from_normalized=C2\n",
    "weights_from_normalized=np.sum(T,axis = 0)\n",
    "X_aligned_from_normalized=np.matmul(T, C2) / weights_from_normalized[:, None]\n",
    "X_aligned_from_normalized = X_aligned_from_normalized.numpy()\n",
    "y_aligned_from_normalized = y_aligned_from_normalized.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee583d2-df95-46ad-911f-647bd2b54e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the average FOSCTTM measure implemented in evals.py for evaluation (metric used in the publication Demetci et al 2021)\n",
    "# This measure reports the fraction of samples closer to a sample than its true match (FOSCTTM), averaged over all samples. \n",
    "fracs_normalized=calc_domainAveraged_FOSCTTM(X_aligned_from_normalized, y_aligned_from_normalized)\n",
    "print(\"Average FOSCTTM score for this alignment with X onto Y is: \", np.mean(fracs_normalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e34227-00b8-4da5-ab70-a842d2983db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d66f554-cdec-4fc6-aff5-2207f8f80179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bec20aa-6e6e-4011-96db-b78cf9ca8ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63941c31-e55a-46a3-a5c4-839ddb077146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9324d52-e009-4e2a-87a2-93dafa0ef8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_metric_learning import losses\n",
    "\n",
    "# create two 5x5 matrices (as PyTorch tensors)\n",
    "matrix1 = torch.randn(5, 6, requires_grad=True)\n",
    "matrix2 = torch.randn(5, 6,requires_grad=True)\n",
    "\n",
    "# Reshape the matrices into 1D tensors and stack them along the first dimension\n",
    "embeddings = torch.stack([matrix1.view(-1), matrix2.view(-1)], dim=0)\n",
    "\n",
    "# Create an instance of the SGD optimizer\n",
    "optimizer = torch.optim.SGD([matrix1, matrix2], lr=0.01)\n",
    "\n",
    "# Create an instance of the VICRegLoss class with default hyperparameters\n",
    "vicreg_loss = pytorch_metric_learning.losses.VICRegLoss()\n",
    "\n",
    "# Loop over a number of epochs\n",
    "num_epochs = 100\n",
    "loss_iter = []\n",
    "for epoch in range(num_epochs):\n",
    "    # Compute the loss\n",
    "     # Zero the gradients of the optimizer\n",
    "    optimizer.zero_grad()\n",
    "    loss = vicreg_loss(embeddings, None, None, embeddings, None)\n",
    "    loss_iter.append(loss.clone().detach().cpu().numpy())\n",
    "    loss.backward()\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Compute the gradients of the loss with respect to the input matrices\n",
    "   # total_loss.backward()\n",
    "    \n",
    "    # Update the input matrices using the optimizer\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print the loss value\n",
    "  #  print(f\"Epoch {epoch+1}/{num_epochs}: loss={total_loss.item()}\") \n",
    "    \n",
    "# Output the optimized matrices\n",
    "matrix1_opt = matrix1.detach().numpy()\n",
    "matrix2_opt = matrix2.detach().numpy()\n",
    "print(\"matrix1_opt:\\n\", matrix1_opt)\n",
    "print(\"matrix2_opt:\\n\", matrix2_opt)\n",
    "pl.figure(2)\n",
    "pl.plot(loss_iter)\n",
    "pl.title(\"Loss along iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720d53f-5859-4364-be54-d8ee398a3129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a431b6be-62fb-4aa2-9f22-72fcbaee08b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b98db59-7d61-46fe-b462-13d4c146ad4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac2a169-be69-4bc7-aba8-955a995db197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import ot\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def lifted_struct_loss(x, y, margin=1.):\n",
    "    \"\"\"\n",
    "    Compute lifted structured loss.\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    dist = euclidean_distances(x, y)\n",
    "    loss = 0.\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                continue\n",
    "            diff = margin - dist[i, j] + dist[i, i]\n",
    "            if diff > 0:\n",
    "                loss += diff\n",
    "    return loss\n",
    "\n",
    "\n",
    "def rank_loss(x, y, lmbda=0.1):\n",
    "    \"\"\"\n",
    "    Compute rank loss.\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    diff = x - y\n",
    "    u, s, v = torch.svd(diff)\n",
    "    s = torch.clamp(s - lmbda, min=0)\n",
    "    rank = torch.sum(s > 0).item()\n",
    "    if rank == 0:\n",
    "        return 0.\n",
    "    return torch.norm(torch.matmul(torch.matmul(u, torch.diag(s)), v.T), p='fro') / rank\n",
    "\n",
    "\n",
    "def optimize_C(C1, C2, p, q, epsilon=1e-2, max_iter=1000, tol=1e-9):\n",
    "    \"\"\"\n",
    "    Optimize C1 and C2 using entropic Gromov-Wasserstein distance.\n",
    "    \"\"\"\n",
    "    n = C1.shape[0]\n",
    "    M = ot.utils.euclidean_distances(np.arange(n)[:, None], np.arange(n)[:, None])\n",
    "    loss_fun = 'square_loss'\n",
    "    reg = 1e-3\n",
    "\n",
    "    def objective(x):\n",
    "        M = x.reshape(n, n)\n",
    "        gw_loss = ot.gromov.entropic_gromov_wasserstein(C1, C2, p, q, loss_fun, epsilon, M=M, log=False, verbose=False, reg=reg)\n",
    "        lsf_loss = lifted_struct_loss(C1, C2)\n",
    "        rank_reg = rank_loss(C1, C2)\n",
    "        return gw_loss + 0.1 * lsf_loss + 0.1 * rank_reg\n",
    "\n",
    "    x0 = np.zeros((n ** 2,))\n",
    "    res = minimize(objective, x0, method='L-BFGS-B', jac=False, options={'maxiter': max_iter, 'tol': tol})\n",
    "    M_opt = res.x.reshape(n, n)\n",
    "    gw_loss_opt = ot.gromov.entropic_gromov_wasserstein(C1, C2, p, q, loss_fun, epsilon, M=M_opt, log=False, verbose=False, reg=reg)\n",
    "    C1_opt = torch.matmul(C1, torch.from_numpy(M_opt).float())\n",
    "    C2_opt = torch.matmul(C2, torch.from_numpy(M_opt).float())\n",
    "    rank_reg_opt = rank_loss(C1_opt, C2_opt)\n",
    "    print('Optimization complete. Gromov-Wasserstein loss: {:.4f}, Lifted Structured loss: {:.4f}, Rank loss: {:.4f}'.format(gw_loss_opt, lifted_struct_loss(C1_opt, C2_opt), rank_reg_opt))\n",
    "    return C1_opt, C2_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee2acdb-3b2f-4db8-bf00-3efa1e0bbd6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d8911-f254-4b80-8bcc-b1ebf449740d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695e70fe-438d-473f-978f-cde280c725ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_metric_learning import losses\n",
    "\n",
    "# Define the two input matrices A1 and A2\n",
    "A1 = torch.randn(10, 10, requires_grad=True)\n",
    "A2 = torch.randn(10, 10, requires_grad=True)\n",
    "\n",
    "# Stack the two matrices along the first dimension to create the embeddings tensor\n",
    "embeddings = torch.stack([A1.view(-1), A2.view(-1)], dim=0)\n",
    "\n",
    "# Create an instance of the SGD optimizer\n",
    "optimizer = torch.optim.SGD([A1, A2], lr=1e-10)\n",
    "\n",
    "# Create an instance of the VICRegLoss class with default hyperparameters\n",
    "vicreg_loss = losses.VICRegLoss()\n",
    "\n",
    "# Loop over a number of epochs\n",
    "num_epochs = 1000\n",
    "loss_iter = []\n",
    "for epoch in range(num_epochs):\n",
    "    # Compute the loss\n",
    "    loss = vicreg_loss(embeddings, None, None, embeddings, None)\n",
    "    #print(loss)\n",
    "    loss_iter.append(loss.clone().detach().cpu().numpy())\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    \n",
    "    # Zero the gradients of the optimizer\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Update the input matrices using the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "# Output the optimized matrices\n",
    "A1_opt = A1.detach().numpy()\n",
    "A2_opt = A2.detach().numpy()\n",
    "# print(\"A1_opt:\\n\", A1_opt)\n",
    "# print(\"A2_opt:\\n\", A2_opt)\n",
    "pl.plot(loss_iter)\n",
    "pl.title(\"Loss along iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcff2df-e326-4dad-9392-d11a8452c149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a756de-55c5-402a-9c20-f4c84155b333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2f235-aee8-4c5d-8862-c25b91fabf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a88e8ac-769e-4a2c-80d2-633e4b328838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb867993-b7f3-494d-bc59-8e8e9ee954d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df983d0-0d6b-4d6c-8438-fda23f1425fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15890f66-9dc9-430f-8d26-ca712c2e76a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e59e24-5727-4f20-962c-328f9342a6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056b7db-0324-482f-8d36-8004622e8600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce31f4-fdd1-497e-b2fc-c9d87ad066bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366645ed-1084-4743-82e1-00fdb4d79cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf9fa18-2482-483b-a3d5-ee600524340a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9ad76-0866-4b62-8bdc-44308009455a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f40847db-8aee-4097-af43-a9fed54f996b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thnguy22/opt/anaconda3/envs/singlecell/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss along iterations')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import pytorch_metric_learning.losses as loss\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "A = torch.randn(5,5)\n",
    "X = A.numpy()  # convert A to numpy array\n",
    "\n",
    "# perform k-means clustering with k=2\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# get the cluster labels and convert them to a tensor\n",
    "labels = kmeans.labels_\n",
    "labels = torch.from_numpy(labels).type(torch.int64)\n",
    "\n",
    "B = torch.randn(5, 5)\n",
    "\n",
    "# Define model\n",
    "model = nn.Linear(5, 5)\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = loss.ProxyAnchorLoss(num_classes=5, embedding_size=5)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.SGD([\n",
    "    {'params': model.parameters()},\n",
    "    {'params': loss_fn.parameters()}\n",
    "], lr=0.1)\n",
    "\n",
    "# Train model\n",
    "loss_iter = []\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    embeddings = model(A)\n",
    "    loss = loss_fn(embeddings, labels)\n",
    "    loss_iter.append(loss.clone().detach().cpu().numpy())\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Extract optimized A and B\n",
    "A_opt = model.weight[:5].detach()\n",
    "B_opt = model.weight[5:].detach()\n",
    "print(A_opt.shape)\n",
    "pl.plot(loss_iter)\n",
    "pl.title(\"Loss along iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3592b0-d978-4847-9933-4a3c6e761803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a343c26-c5dd-4cfe-b302-2f794902ef5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b8861-59d3-417e-bfa4-4f0d28a6d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import pytorch_metric_learning.losses as loss\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "A = torch.randn(1000,1000)\n",
    "X = A.numpy()  # convert A to numpy array\n",
    "\n",
    "# perform k-means clustering with k=2\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# get the cluster labels and convert them to a tensor\n",
    "labels = kmeans.labels_\n",
    "labels = torch.from_numpy(labels).type(torch.int64)\n",
    "\n",
    "# B = torch.randn(5, 5)\n",
    "\n",
    "# Define model\n",
    "model = nn.Linear(1000, 1000)\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = loss.LiftedStructureLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.SGD([\n",
    "    {'params': model.parameters()},\n",
    "    {'params': loss_fn.parameters()}\n",
    "], lr=0.1)\n",
    "\n",
    "# Train model\n",
    "loss_iter = []\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    embeddings = model(A)\n",
    "    loss = loss_fn(embeddings, labels)\n",
    "    loss_iter.append(loss.clone().detach().cpu().numpy())\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Extract optimized A and B\n",
    "A_opt = model.weight[:5].detach()\n",
    "B_opt = model.weight[5:].detach()\n",
    "pl.plot(loss_iter)\n",
    "pl.title(\"Loss along iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b8168-e62a-4740-baa2-502b0812712a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12d2e03-8359-4b53-b3d3-7bced5517d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af22b23-9f34-4904-81ab-7d2bb78862d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a03a2b3-d2d4-4224-90f2-9246f9fc6d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55927ab-a678-4a79-869a-91d00d7bcca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f54991-43c1-4df9-9b41-1fa9a2bfa8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7195fa6f-9ab4-415e-8af0-1b8d80d5a073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9097a512-68a9-43df-8acb-a64389f5bedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67ded0-96fe-4ece-aa1c-f41f8e730303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c2db42-34b3-4898-ba6a-fa01710eed1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0357b73a-bd57-47b6-a546-792ac8f213f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e79414-834e-49ee-885b-4a9bac8cda17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105fd091-75f8-47a7-9829-afdaebbcc7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_metric_learning import losses\n",
    "\n",
    "# create two 5x5 matrices (as PyTorch tensors)\n",
    "matrix1 = torch.randn(5, 6, requires_grad=True)\n",
    "matrix2 = torch.randn(5, 6,requires_grad=True)\n",
    "\n",
    "# Reshape the matrices into 1D tensors and stack them along the first dimension\n",
    "embeddings = torch.stack([matrix1.view(-1), matrix2.view(-1)], dim=0)\n",
    "\n",
    "# Create an instance of the SGD optimizer\n",
    "optimizer = torch.optim.SGD([matrix1, matrix2], lr=0.01)\n",
    "\n",
    "# Create an instance of the VICRegLoss class with default hyperparameters\n",
    "vicreg_loss = losses.VICRegLoss()\n",
    "\n",
    "# Loop over a number of epochs\n",
    "num_epochs = 100\n",
    "loss_iter = []\n",
    "for epoch in range(num_epochs):\n",
    "    # Compute the loss\n",
    "    loss = vicreg_loss(embeddings, None, None, embeddings, None)\n",
    "    loss_iter.append(loss.clone().detach().cpu().numpy())\n",
    "    loss.backward()\n",
    "    \n",
    "    # Zero the gradients of the optimizer\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Compute the gradients of the loss with respect to the input matrices\n",
    "   # total_loss.backward()\n",
    "    \n",
    "    # Update the input matrices using the optimizer\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print the loss value\n",
    "  #  print(f\"Epoch {epoch+1}/{num_epochs}: loss={total_loss.item()}\") \n",
    "    \n",
    "# Output the optimized matrices\n",
    "matrix1_opt = matrix1.detach().numpy()\n",
    "matrix2_opt = matrix2.detach().numpy()\n",
    "print(\"matrix1_opt:\\n\", matrix1_opt)\n",
    "print(\"matrix2_opt:\\n\", matrix2_opt)\n",
    "pl.figure(2)\n",
    "pl.plot(loss_iter)\n",
    "pl.title(\"Loss along iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b4783-7c20-46a0-8913-900a0c375f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63f60a-35fd-4431-bd9f-8e2ca4f5d0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de99933-d3fc-4531-94ef-8eebcb14b8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6a2aac-143c-4140-af82-e2212c6cf756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "class ContrastiveLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, temperature):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        batch_size = z_i.shape[0]\n",
    "        z_i = z_i.view(batch_size, -1)\n",
    "        z_j = z_j.view(batch_size, -1)\n",
    "        z = torch.cat([z_i, z_j], dim=0)\n",
    "        sim = torch.matmul(z, z.t()) / self.temperature\n",
    "        sim_i_j = torch.diag(sim, batch_size)\n",
    "        sim_j_i = torch.diag(sim, -batch_size)\n",
    "        pos = torch.cat([sim_i_j, sim_j_i], dim=0)\n",
    "        neg = sim.exp().sum(dim=1) - sim_i_j.exp().diag()\n",
    "        loss = (-torch.log(sim_i_j.exp() / neg)).mean()\n",
    "        return loss\n",
    "\n",
    "# Create two 5x5 matrices (as PyTorch tensors)\n",
    "matrix1 = torch.randn(5, 5)\n",
    "matrix2 = torch.randn(5, 5)\n",
    "\n",
    "# Reshape the matrices into 1D tensors (required by the encoder)\n",
    "x_i = matrix1.view(-1)\n",
    "x_j = matrix2.view(-1)\n",
    "\n",
    "# Instantiate the encoder and contrastive loss\n",
    "encoder = Encoder(input_dim=25, output_dim=25)  # fixed input_dim and output_dim\n",
    "contrastive_loss = ContrastiveLoss(temperature=0.5)\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = torch.optim.SGD(encoder.parameters(), lr=0.01)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 1000\n",
    "\n",
    "# Train the encoder using Deep InfoMax\n",
    "for epoch in range(num_epochs):\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    z_i = encoder(x_i.unsqueeze(0))\n",
    "    z_j = encoder(x_j.unsqueeze(0))\n",
    "    \n",
    "    # Compute the contrastive loss\n",
    "    loss = contrastive_loss(z_i, z_j)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss\n",
    "    # print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Get the learned embeddings\n",
    "z_i = encoder(x_i.unsqueeze(0)).detach().numpy()\n",
    "z_j = encoder(x_j.unsqueeze(0)).detach().numpy()\n",
    "\n",
    "# Reshape the embeddings into 5x5 matrices\n",
    "matrix1_opt = torch.tensor(z_i).view(5, 5)\n",
    "matrix2_opt = torch.tensor(z_j).view(5, 5)\n",
    "\n",
    "# Print the optimized matrices\n",
    "print(\"Matrix 1 optimized:\\n\", matrix1_opt.shape)\n",
    "print(\"Matrix 2 optimized:\\n\", matrix2_opt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79dbcc1-90a5-4eb0-8b5e-bf91a88d66d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d5764-9f88-4dd2-a489-479731ebd168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "    \n",
    "class ContrastiveLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, temperature):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        batch_size = z_i.shape[0]\n",
    "        z_i = z_i.view(batch_size, -1)\n",
    "        z_j = z_j.view(batch_size, -1)\n",
    "        z = torch.cat([z_i, z_j], dim=0)\n",
    "        sim = torch.matmul(z, z.t()) / self.temperature\n",
    "        sim_i_j = torch.diag(sim, batch_size)\n",
    "        sim_j_i = torch.diag(sim, -batch_size)\n",
    "        pos = torch.cat([sim_i_j, sim_j_i], dim=0)\n",
    "        neg = sim.exp().sum(dim=1) - sim_i_j.exp().diag()\n",
    "        loss = (-torch.log(sim_i_j.exp() / neg)).mean()\n",
    "        return loss\n",
    "\n",
    "# Create two 5x5 matrices (as PyTorch tensors)\n",
    "matrix1 = torch.randn(5, 5)\n",
    "matrix2 = torch.randn(5, 5)\n",
    "\n",
    "# Reshape the matrices into 1D tensors (required by the encoder)\n",
    "x_i = matrix1.view(-1)\n",
    "x_j = matrix2.view(-1)\n",
    "\n",
    "# Instantiate the encoder and contrastive loss\n",
    "encoder = Encoder(input_dim=25, output_dim=25)  # fixed input_dim and output_dim\n",
    "contrastive_loss = ContrastiveLoss(temperature=0.5)\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = torch.optim.SGD(encoder.parameters(), lr=0.01)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 1000\n",
    "\n",
    "# Train the encoder using contrasitive loss\n",
    "for epoch in range(num_epochs):\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    z_i = encoder(x_i.unsqueeze(0))\n",
    "    z_j = encoder(x_j.unsqueeze(0))\n",
    "    \n",
    "    # Compute the contrastive loss\n",
    "    loss = contrastive_loss(z_i, z_j)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss\n",
    "    # print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Get the learned embeddings\n",
    "z_i = encoder(x_i.unsqueeze(0)).detach().numpy()\n",
    "z_j = encoder(x_j.unsqueeze(0)).detach().numpy()\n",
    "\n",
    "# Reshape the embeddings into 5x5 matrices\n",
    "matrix1_opt = torch.tensor(z_i).view(5, 5)\n",
    "matrix2_opt = torch.tensor(z_j).view(5, 5)\n",
    "\n",
    "print(\"Matrix 1 optimized:\\n\", matrix1_opt)\n",
    "print(\"Matrix 2 optimized:\\n\", matrix2_opt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb836bc3-0bfe-44f7-b254-84dd5736ac66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220445b-3e9b-416b-9a86-6c5c7280c7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12424599-c976-4932-a677-7cbddd1a734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        batch_size = z_i.shape[0]\n",
    "        z_i = z_i.view(batch_size, -1)\n",
    "        z_j = z_j.view(batch_size, -1)\n",
    "        z = torch.cat([z_i, z_j], dim=0)\n",
    "        sim = torch.matmul(z, z.t()) / self.temperature\n",
    "        sim_i_j = torch.diag(sim, batch_size)\n",
    "        sim_j_i = torch.diag(sim, -batch_size)\n",
    "        pos = torch.cat([sim_i_j, sim_j_i], dim=0)\n",
    "        neg = sim.exp().sum(dim=1) - sim_i_j.exp().diag()\n",
    "        loss = (-torch.log(sim_i_j.exp() / neg)).mean()\n",
    "        return loss\n",
    "\n",
    "class VICRegLoss(nn.Module):\n",
    "    def __init__(self, lamda):\n",
    "        super(VICRegLoss, self).__init__()\n",
    "        self.lamda = lamda\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        batch_size = z_i.shape[0]\n",
    "        z_i = z_i.view(batch_size, -1)\n",
    "        z_j = z_j.view(batch_size, -1)\n",
    "        z = torch.cat([z_i, z_j], dim=0)\n",
    "        z_mean = z.mean(dim=0)\n",
    "        loss = ((z - z_mean)**2).sum(dim=1).mean()\n",
    "        return self.lamda * loss\n",
    "\n",
    "# Create two 5x5 matrices (as PyTorch tensors)\n",
    "matrix1 = torch.randn(5, 5)\n",
    "matrix2 = torch.randn(5, 5)\n",
    "\n",
    "# Reshape the matrices into 1D tensors (required by the encoder)\n",
    "x_i = matrix1.view(-1)\n",
    "x_j = matrix2.view(-1)\n",
    "\n",
    "# Instantiate the encoder, contrastive loss, and VICReg loss\n",
    "encoder = Encoder(input_dim=25, output_dim=25)  # fixed input_dim and output_dim\n",
    "contrastive_loss = ContrastiveLoss(temperature=0.5)\n",
    "vicreg_loss = VICRegLoss(lamda=0.1)\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = torch.optim.SGD(encoder.parameters(), lr=0.01)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 1000\n",
    "\n",
    "# Train the encoder using Deep InfoMax\n",
    "for epoch in range(num_epochs):\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    z_i = encoder(x_i.unsqueeze(0))\n",
    "    z_j = encoder(x_j.unsqueeze(0))\n",
    "    \n",
    "    # Compute the loss\n",
    "    contrastive_loss_val = contrastive_loss(z_i, z_j)\n",
    "    vicreg_loss_val = vicreg_loss(z_i, z_j)\n",
    "    loss = contrastive_loss_val + vicreg_loss_val\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print\n",
    "# Get the learned embeddings\n",
    "z_i = encoder(x_i.unsqueeze(0)).detach().numpy()\n",
    "z_j = encoder(x_j.unsqueeze(0)).detach().numpy()\n",
    "\n",
    "# Reshape the embeddings into 5x5 matrices\n",
    "matrix1_opt = torch.tensor(z_i).view(5, 5)\n",
    "matrix2_opt = torch.tensor(z_j).view(5, 5)\n",
    "\n",
    "print(\"Matrix 1 optimized:\\n\", matrix1_opt)\n",
    "print(\"Matrix 2 optimized:\\n\", matrix2_opt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d799f-c6b5-4a9d-b3df-ee6a24ebee53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee8b955-b99e-42ae-a9de-7e4741ba2bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a408293c-f0c9-4a89-97ef-be47904fc812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_metric_learning import losses, miners\n",
    "\n",
    "# Define the input matrix\n",
    "input_matrix = torch.randn(5, 5)\n",
    "\n",
    "# Define the pairs of indices\n",
    "pairs = [(0, 1), (0, 2), (0, 3)]\n",
    "\n",
    "# Define the embedding network\n",
    "embedding_network = torch.nn.Linear(5, 2)\n",
    "\n",
    "# Define the loss function\n",
    "loss_func = losses.TripletMarginLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(embedding_network.parameters(), lr=0.001)\n",
    "\n",
    "# Train the embedding network\n",
    "for epoch in range(10):\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    embeddings = embedding_network(input_matrix)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = loss_func(embeddings, indices_tuple=pairs)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss\n",
    "    print(\"Epoch {}: Loss = {}\".format(epoch, loss.item()))\n",
    "\n",
    "# Get the learned embedding matrix\n",
    "embedding_matrix = embedding_network.weight.detach().numpy()\n",
    "print(\"Learned embedding matrix:\")\n",
    "print(embedding_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bbfa73-6c52-4568-b48f-1707c8f609e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc02f0d-06a8-418c-92a6-a01ed3b9c1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473f9326-e048-49a7-8349-ccd36469f89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd472ef2-b1b8-4ba7-8341-fecf94ced29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thnguy22/opt/anaconda3/envs/singlecell/lib/python3.8/site-packages/sklearn/manifold/_mds.py:299: FutureWarning: The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.3028101 , 0.20249103, 0.49469887])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import MDS\n",
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "import torch\n",
    "\n",
    "import ot\n",
    "from ot.gromov import gromov_wasserstein2\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "\n",
    "def get_sbm(n, nc, ratio, P):\n",
    "    nbpc = np.round(n * ratio).astype(int)\n",
    "    n = np.sum(nbpc)\n",
    "    C = np.zeros((n, n))\n",
    "    for c1 in range(nc):\n",
    "        for c2 in range(c1 + 1):\n",
    "            if c1 == c2:\n",
    "                for i in range(np.sum(nbpc[:c1]), np.sum(nbpc[:c1 + 1])):\n",
    "                    for j in range(np.sum(nbpc[:c2]), i):\n",
    "                        if rng.rand() <= P[c1, c2]:\n",
    "                            C[i, j] = 1\n",
    "            else:\n",
    "                for i in range(np.sum(nbpc[:c1]), np.sum(nbpc[:c1 + 1])):\n",
    "                    for j in range(np.sum(nbpc[:c2]), np.sum(nbpc[:c2 + 1])):\n",
    "                        if rng.rand() <= P[c1, c2]:\n",
    "                            C[i, j] = 1\n",
    "\n",
    "    return C + C.T\n",
    "\n",
    "\n",
    "n = 100\n",
    "nc = 3\n",
    "ratio = np.array([.5, .3, .2])\n",
    "P = np.array(0.6 * np.eye(3) + 0.05 * np.ones((3, 3)))\n",
    "C1 = get_sbm(n, nc, ratio, P)\n",
    "\n",
    "# get 2d position for nodes\n",
    "x1 = MDS(dissimilarity='precomputed', random_state=0).fit_transform(1 - C1)\n",
    "\n",
    "\n",
    "C0 = np.eye(3) \n",
    "\n",
    "def min_weight_gw(C1, C2, a2, nb_iter_max=100, lr=1e-2):\n",
    "    \"\"\" solve min_a GW(C1,C2,a, a2) by gradient descent\"\"\"\n",
    "\n",
    "    # use pyTorch for our data\n",
    "    C1_torch = torch.tensor(C1)\n",
    "    C2_torch = torch.tensor(C2)\n",
    "\n",
    "    a0 = rng.rand(C1.shape[0])  # random_init\n",
    "    a0 /= a0.sum()  # on simplex\n",
    "    a1_torch = torch.tensor(a0).requires_grad_(True)\n",
    "    a2_torch = torch.tensor(a2)\n",
    "\n",
    "    loss_iter = []\n",
    "\n",
    "    for i in range(nb_iter_max):\n",
    "\n",
    "        loss = gromov_wasserstein2(C1_torch, C2_torch, a1_torch, a2_torch)\n",
    "\n",
    "        loss_iter.append(loss.clone().detach().cpu().numpy())\n",
    "        loss.backward()\n",
    "\n",
    "        #print(\"{:03d} | {}\".format(i, loss_iter[-1]))\n",
    "\n",
    "        # performs a step of projected gradient descent\n",
    "        with torch.no_grad():\n",
    "            grad = a1_torch.grad\n",
    "            a1_torch -= grad * lr   # step\n",
    "            a1_torch.grad.zero_()\n",
    "            a1_torch.data = ot.utils.proj_simplex(a1_torch)\n",
    "\n",
    "    a1 = a1_torch.clone().detach().cpu().numpy()\n",
    "\n",
    "    return a1, loss_iter\n",
    "\n",
    "\n",
    "a0_est, loss_iter0 = min_weight_gw(C0, C1, ot.unif(n), nb_iter_max=100, lr=1e-2)\n",
    "\n",
    "pl.figure(2)\n",
    "pl.plot(loss_iter0)\n",
    "pl.title(\"Loss along iterations\")\n",
    "a0_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ad53e1-46cf-4fbf-ad9a-d805f79f5345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2a4ed-67a3-4679-85f7-6922a9d85188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1286e32-5c6d-499c-b07d-13bac35d79cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a102485e-7c9a-4bba-a6c0-f062a93b37af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30207516, 0.20177297, 0.49615188])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def min_weight_gw(C1, C2, a2, nb_iter_max=100, lr=1e-2):\n",
    "    \"\"\" solve min_a GW(C1,C2,a, a2) by gradient descent\"\"\"\n",
    "\n",
    "    # use PyTorch for our data\n",
    "    C1_torch = torch.tensor(C1)\n",
    "    C2_torch = torch.tensor(C2)\n",
    "\n",
    "    a0 = rng.rand(C1.shape[0])  # random_init\n",
    "    a0 /= a0.sum()  # on simplex\n",
    "    a1_torch = torch.tensor(a0).requires_grad_(True)\n",
    "    a2_torch = torch.tensor(a2)\n",
    "\n",
    "    # Define the SGD optimizer\n",
    "    optimizer = optim.SGD([a1_torch], lr=lr)\n",
    "\n",
    "    loss_iter = []\n",
    "\n",
    "    for i in range(nb_iter_max):\n",
    "\n",
    "        loss = gromov_wasserstein2(C1_torch, C2_torch, a1_torch, a2_torch)\n",
    "\n",
    "        loss_iter.append(loss.clone().detach().cpu().numpy())\n",
    "\n",
    "        # Backpropagate the loss and update the weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Project the weights onto the simplex\n",
    "        with torch.no_grad():\n",
    "            a1_torch.data = ot.utils.proj_simplex(a1_torch)\n",
    "\n",
    "    a1 = a1_torch.clone().detach().cpu().numpy()\n",
    "\n",
    "    return a1, loss_iter\n",
    "\n",
    "a0_est, loss_iter0 = min_weight_gw(C0, C1, ot.unif(n), nb_iter_max=100, lr=1e-2)\n",
    "\n",
    "pl.figure(2)\n",
    "pl.plot(loss_iter0)\n",
    "pl.title(\"Loss along iterations\")\n",
    "a0_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e70c69-a1df-473e-963b-a53e4352bc18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db72964-4201-483b-a436-07161b6ebe34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6879dd-8ba9-4d1f-a6c2-884251ca8f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1311456-ccb0-4206-b8f7-d69a94929b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c405ce90-8f0a-44dc-9479-275524fe8bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530cdd70-9465-433a-ac42-070379cf40be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb357d8-444b-4266-a561-30c5f042b039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cdeac8-8fdd-477f-ae0f-abf8e2564cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e5891-7966-4b67-bf3c-38479d09c9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2fb3f4-51b7-4601-899f-b353b382f3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a0c8ce-5f7b-4bd4-9e64-6cc59af69a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e277e-71fd-483e-9436-08598bd4cc48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e89f45-89ab-4522-83f9-e5e9d4475fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ecc17e-56be-4dba-b16a-6064b97efbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1cb02e-d380-4950-b555-f6ccb241a4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d048dd98-bc3b-4af0-9a71-d2ded9dbf5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b47342-f253-49dd-b6ae-1e12d8dff2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0be7b7-f463-4f72-bf69-c15586ec3e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09c9709-7d7a-452f-90b4-3c983606d87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c99f163-2941-47b7-b768-815fc7dac693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input matrix:\n",
      "tensor([[-0.2771, -1.3754, -0.7247, -0.6752, -0.9826],\n",
      "        [-0.4572, -2.4291, -0.4180, -0.8926, -1.7387],\n",
      "        [-0.2092,  2.7644, -1.2251, -0.0748,  0.0965],\n",
      "        [-0.6140, -0.0636, -0.2082, -1.0702,  0.3286],\n",
      "        [ 0.9890,  0.2664, -0.2366,  1.7355, -0.0759]])\n",
      "Output matrix:\n",
      "tensor([[-0.2771, -1.3754, -0.7247, -0.6752, -0.9826],\n",
      "        [-0.4572, -2.4291, -0.4180, -0.8926, -1.7387],\n",
      "        [-0.2092,  2.7644, -1.2251, -0.0748,  0.0965],\n",
      "        [-0.6140, -0.0636, -0.2082, -1.0702,  0.3286],\n",
      "        [ 0.9890,  0.2664, -0.2366,  1.7355, -0.0759]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Define the input matrix\n",
    "input_matrix = torch.randn(5, 5)\n",
    "\n",
    "# Compute the SVD of the input matrix\n",
    "u, s, v = torch.svd(input_matrix)\n",
    "\n",
    "# Compute the rank of the input matrix\n",
    "rank = torch.sum(s > 0.01)\n",
    "\n",
    "# Construct a low-rank approximation of the input matrix\n",
    "output_matrix = torch.matmul(u[:, :rank], torch.matmul(torch.diag(s[:rank]), v[:, :rank].T))\n",
    "\n",
    "print(\"Input matrix:\")\n",
    "print(input_matrix)\n",
    "\n",
    "print(\"Output matrix:\")\n",
    "print(output_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f112b5-bf17-4863-b3cd-d7d887f96eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cc21c-9c41-4bba-9584-5aacebd222bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507459d5-be41-4c24-9509-29958fdf76a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29def144-63f0-4ddb-b3f3-4ff3e2c21686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_metric_learning.losses\n",
    "\n",
    "# Define the input matrix\n",
    "input_matrix = torch.randn(5, 5)\n",
    "\n",
    "# Define the embedding network\n",
    "embedding_network = torch.nn.Linear(5, 2)\n",
    "\n",
    "# Define the loss function\n",
    "loss_func = pytorch_metric_learning.losses.AngularLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(embedding_network.parameters(), lr=0.001)\n",
    "\n",
    "# Define the labels (assuming there are 3 classes)\n",
    "labels = torch.tensor([0, 1, 2, 1, 0])\n",
    "\n",
    "loss_iter = []\n",
    "# Train the embedding network\n",
    "for epoch in range(10):\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    embeddings = embedding_network(input_matrix)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = loss_func(embeddings, labels)\n",
    "    \n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss\n",
    "    print(\"Epoch {}: Loss = {}\".format(epoch, loss.item()))\n",
    "\n",
    "# Get the learned embedding matrix\n",
    "embedding_matrix = embedding_network.weight.detach().numpy()\n",
    "print(\"Learned embedding matrix:\")\n",
    "print(embedding_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e708f541-a25f-4037-9acd-e2e93ecadd69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaacb9d4-c0a0-452f-9a4b-6d5b7db4e60b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a3413e-eff6-4d8b-90d8-3ec8718c1517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "class KMeansClustering:\n",
    "    def __init__(self, n_clusters):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.kmeans = KMeans(n_clusters=n_clusters)\n",
    "        \n",
    "    def __call__(self, embeddings):\n",
    "        batch_size = embeddings.size(0)\n",
    "        embeddings_np = embeddings.detach().cpu().numpy().reshape(batch_size, -1)\n",
    "        cluster_labels = self.kmeans.fit_predict(embeddings_np)\n",
    "        return torch.tensor(cluster_labels)\n",
    "\n",
    "# Define the input matrix\n",
    "input_matrix = torch.randn(5, 5)\n",
    "\n",
    "# Define the embedding network\n",
    "embedding_network = torch.nn.Linear(5, 2)\n",
    "\n",
    "# Define the clustering algorithm\n",
    "clustering_algo = KMeansClustering(3)\n",
    "\n",
    "# Cluster the input vectors\n",
    "clusters = clustering_algo(embedding_network(input_matrix))\n",
    "\n",
    "# Print the cluster assignments\n",
    "print(\"Cluster assignments:\")\n",
    "print(clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d951c7d-5857-4729-a3b3-048d73d71995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a791dd71-30f8-494c-9257-8fbf009cf09e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c7742-83c5-4252-893b-6e0b5bb810bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import geomloss\n",
    "\n",
    "# Define the input samples\n",
    "X = torch.randn(100, 2)\n",
    "Y = torch.randn(200, 2)\n",
    "\n",
    "# Define the loss function\n",
    "loss = geomloss.SamplesLoss(\"sinkhorn\", p=2)\n",
    "\n",
    "# Compute the Wasserstein distance between the two samples\n",
    "w_distance = loss(X, Y)\n",
    "\n",
    "print(\"The Wasserstein distance between X and Y is:\", w_distance.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f759a60-a5d3-4324-8374-241bee029e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d243663-c0d7-41c2-a4c7-dd5ef1c3ec2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f992c-9fe3-4020-9972-b27e7d3bc9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import geomloss\n",
    "\n",
    "# define the inputs\n",
    "C1 = torch.randn(5, 12)\n",
    "C2 = torch.randn(6, 12)\n",
    "\n",
    "# define the loss function\n",
    "loss = geomloss.SamplesLoss(loss=\"sinkhorn\", p=2, blur=0.05)\n",
    "\n",
    "# define the optimization function\n",
    "def optimize(C1, C2, lr=0.1, num_steps=1000):\n",
    "    # initialize C1 and C2\n",
    "    C1 = torch.nn.Parameter(C1)\n",
    "    C2 = torch.nn.Parameter(C2)\n",
    "\n",
    "    # define the optimizer\n",
    "    optimizer = torch.optim.SGD([C1, C2], lr=lr)\n",
    "\n",
    "    # optimize the loss\n",
    "    for i in range(num_steps):\n",
    "        optimizer.zero_grad()\n",
    "        loss_value = loss(C1, C2)\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return C1.detach().numpy(), C2.detach().numpy()\n",
    "\n",
    "# optimize C1 and C2\n",
    "C1_opt, C2_opt = optimize(C1, C2)\n",
    "\n",
    "# compute the loss on the optimized C1 and C2\n",
    "loss_value = loss(torch.tensor(C1_opt), torch.tensor(C2_opt))\n",
    "print(C1_opt.shape)\n",
    "print(C2_opt.shape)\n",
    "# print(f\"Optimal C1:\\n{C1_opt}\")\n",
    "# print(f\"Optimal C2:\\n{C2_opt}\")\n",
    "print(f\"Optimal loss: {loss_value.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988741aa-1ed1-4ea1-915a-21d345b0fdbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0644f151-8472-4647-9e08-3c063a8eaca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f49dd-c471-4950-aed8-75940ad88050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c14c0e-1332-4114-b616-19de756a108c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa904248-84a5-4b5a-a723-6d67ddfff085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8ba1e-d502-42c7-a89e-a0ab6dbdf38a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36672ec9-a87d-4b98-83d0-68b1d8d53070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16098d44-5266-4c09-840b-8b2900ff99af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d42a1-5e6f-4ac8-a1e1-419c05e85f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6571fc76-0bb9-4c5e-9ec3-eb8fc220b4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56431e3a-ef6d-4442-9c7a-1a1a04352e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48776acf-1cae-493a-9cbf-ea267eba6b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686e3430-13f1-43e3-a33e-ca28c428cad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4acb756-7a68-410e-8911-e802450f78e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606f404a-ff36-4c35-8ace-8ebbcef6a519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0248271-3d18-4a46-a662-3bc3e716a19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14ed91-9a64-4027-ba55-c0eccde99f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4509ef55-1ea7-446d-904a-e8194f4b2720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c5d76-c7c0-4c5f-97e1-c1e31e476781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4c2ee1-7e0e-41da-b071-2bb184cea4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05661be2-6431-405e-a793-38585156a47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c6c51-6e8c-4e98-a6cf-42bbc56abe8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b1907-1fca-4804-8f77-e57051256f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd5aaf-786d-4635-85d5-626271118471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8112d-c123-4f6c-8445-0b18b592ce5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd235db6-eae1-4e11-bbf3-e452a1150b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import geomloss\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define a function to compute the Wasserstein distance using geomloss\n",
    "def gw_dist(x, y):\n",
    "    x_tensor = torch.tensor(x, dtype=torch.float32).view(-1, 1)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "    loss = geomloss.SamplesLoss(\"sinkhorn\", p=2, blur=0.05)\n",
    "    return loss(x_tensor, y_tensor)\n",
    "\n",
    "# Define the objective function to be minimized\n",
    "def objective(x):\n",
    "    return gw_dist(x, [0.5, 0.5])\n",
    "\n",
    "# Set the initial guess for x\n",
    "x0 = [0.1, 0.9]\n",
    "\n",
    "# Minimize the function using L-BFGS-B algorithm\n",
    "result = minimize(objective, x0,  method='L-BFGS-B', bounds=[(0, 1), (0, 1)])\n",
    "\n",
    "# Print the result\n",
    "print(result)\n",
    "\n",
    "# Print the optimized point and minimum value\n",
    "print(\"Optimized point:\", result.x)\n",
    "\n",
    "print(\"Minimum value:\", result.fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7585214c-8e25-4cb2-89c3-378a4486e67f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6736fc7f-ee9a-400d-a05b-5d70c1c2fb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b17cff-8106-4cf8-82d1-bbe0eeb162c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import geomloss\n",
    "\n",
    "# Generate a random matrix\n",
    "X = torch.randn(5, 5)\n",
    "\n",
    "# Define the cost function for the Gromov-Wasserstein distance\n",
    "def cost(x, y):\n",
    "    return (x - y)**2\n",
    "\n",
    "# Define the distance function for the Gromov-Wasserstein distance\n",
    "def dist(x, y):\n",
    "    return torch.abs(x - y)\n",
    "\n",
    "# Calculate the Gromov-Wasserstein distance\n",
    "GW_loss = geomloss.SamplesLoss(loss=\"sinkhorn\", p=2, blur=0.1, scaling=0.9)\n",
    "dist_mat = GW_loss(X.unsqueeze(0), X.unsqueeze(0)).detach().numpy()\n",
    "print(dist_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe5513d-b111-4318-8da7-ccaa58921821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee836a-6773-44f3-965d-1c4a9ade173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Compute the most similar matrix to a given input matrix using SVD\n",
    "def compute_similar_matrix(input_matrix):\n",
    "    # Compute the singular value decomposition of the input matrix\n",
    "    U, S, V = torch.svd(input_matrix)\n",
    "\n",
    "    # Construct the diagonal matrix of singular values\n",
    "    S_matrix = torch.zeros((input_matrix.shape[0], input_matrix.shape[1]))\n",
    "    S_matrix[:S.shape[0], :S.shape[0]] = torch.diag(S)\n",
    "\n",
    "    # Compute the most similar matrix to the input matrix using SVD\n",
    "    similar_matrix = torch.mm(torch.mm(U, S_matrix), V.t())\n",
    "\n",
    "    return similar_matrix\n",
    "\n",
    "# Example usage\n",
    "input_matrix = torch.randn(5, 5)\n",
    "similar_matrix = compute_similar_matrix(input_matrix)\n",
    "print(\"Input matrix:\")\n",
    "print(input_matrix)\n",
    "print(\"Similar matrix:\")\n",
    "print(similar_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d57af1-279f-44af-a47d-201f689ca40a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42914c2-4d3b-4e6c-934a-b55eb2bcf47b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81d347f-6b36-403a-aad9-9b3781db9936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d648b1-b758-44f9-85ae-dca03beebc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(25, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(4, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 25),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the autoencoder\n",
    "autoencoder = Autoencoder()\n",
    "\n",
    "# Define a loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.01)\n",
    "\n",
    "# Generate some example input data\n",
    "input_data = torch.randn(5, 5)\n",
    "\n",
    "# Train the autoencoder to output a similar matrix\n",
    "for epoch in range(1000):\n",
    "    # Reset the optimizer gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass through the autoencoder\n",
    "    output_data = autoencoder(input_data.view(1, -1)).view(5, 5)\n",
    "\n",
    "    # Compute the loss and perform backpropagation\n",
    "    loss = criterion(output_data, input_data)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item()}\")\n",
    "\n",
    "# Evaluate the autoencoder on some test data\n",
    "test_input_data = torch.randn(5, 5)\n",
    "test_output_data = autoencoder(test_input_data.view(1, -1)).view(5, 5)\n",
    "print(f\"Input data:\\n{test_input_data}\")\n",
    "print(f\"Output data:\\n{test_output_data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee2dc8-4d7b-4117-94d1-5b7a2ef74079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765f39d-16c5-4a91-a0b0-6051b04c8c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac7cf57-8546-44be-a946-8639c784dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Define the network architecture\n",
    "class MetricNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MetricNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# Define the loss function\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=0.2):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, pos, neg):\n",
    "        pos_dist = torch.sum(torch.pow(anchor - pos, 2), dim=1)\n",
    "        neg_dist = torch.sum(torch.pow(anchor - neg, 2), dim=1)\n",
    "        loss = torch.mean(torch.max(pos_dist - neg_dist + self.margin, torch.tensor([0.]).to(device)))\n",
    "        return loss\n",
    "\n",
    "# Define the Siamese network and the optimizer\n",
    "net = MetricNet().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Generate the input data\n",
    "x = torch.randn(5, 5).to(device)\n",
    "\n",
    "# Train the network for one epoch\n",
    "net.train()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "anchor = net(x)\n",
    "pos = net(x)\n",
    "neg = net(x)\n",
    "\n",
    "loss_fn = TripletLoss()\n",
    "loss = loss_fn(anchor, pos, neg)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# Get the output of the network\n",
    "net.eval()\n",
    "output = net(x)\n",
    "print('x is',x)\n",
    "print('output is', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b3b89-228a-4028-b507-5c92e66acb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fd9b08-15e2-4b06-9442-923341b9e7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39566754-93d2-4434-9356-03fb991a86de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb51a59-0a2d-4c8e-884c-2a17d7512d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the model architecture\n",
    "class MetricNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MetricNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 2)\n",
    "        self.fc2 = nn.Linear(2, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the training parameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 1\n",
    "num_epochs = 1000\n",
    "\n",
    "# Create the model and move it to the device\n",
    "model = MetricNet()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Generate the input data\n",
    "input_data = torch.randn(5, 5).to(device)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Generate a random batch of data\n",
    "    data = input_data.view(-1, 5).repeat(batch_size, 1)\n",
    "    target = data.clone()\n",
    "    \n",
    "    # Move the data to the device\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Get the output\n",
    "print('x is', x)\n",
    "output_data = model(input_data.view(-1, 5)).view(5, 5)\n",
    "print(output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7b93f-454f-4a0d-a986-3acb7edf3507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b177452-1a93-4592-ad46-0041af4e07a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the model architecture\n",
    "class LiftedStructureEmbedding(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LiftedStructureEmbedding, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(5, 32)\n",
    "        self.fc2 = torch.nn.Linear(32, 16)\n",
    "        self.fc3 = torch.nn.Linear(16, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        h = self.fc3(h)\n",
    "        return h\n",
    "\n",
    "# Define the loss function\n",
    "def lifted_structure_loss(x, y, margin=1):\n",
    "    # Compute the pairwise distances between the embeddings\n",
    "    pairwise_dist = torch.cdist(x, x, p=2)\n",
    "    # Compute the mask for same and different class pairs\n",
    "    mask = (y.unsqueeze(0) == y.unsqueeze(1)).float()\n",
    "    neg_mask = (1 - mask).bool()\n",
    "    # Compute the loss\n",
    "    pos_loss = torch.sum((pairwise_dist * mask) ** 2) / torch.sum(mask)\n",
    "    neg_loss = torch.sum(F.relu(margin - pairwise_dist[neg_mask]) ** 2) / torch.sum(neg_mask)\n",
    "    loss = pos_loss + neg_loss\n",
    "    return loss\n",
    "\n",
    "# Generate the input data\n",
    "x = torch.randn(5, 5)\n",
    "\n",
    "# Define the model and move it to the GPU\n",
    "model = LiftedStructureEmbedding()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    embeddings = model(x.to(device))\n",
    "    # Compute the loss\n",
    "    loss = lifted_structure_loss(embeddings, torch.arange(5).to(device))\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update the weights\n",
    "    optimizer.step()\n",
    "\n",
    "# Generate the output data\n",
    "print(x)\n",
    "output = model(x.to(device)).detach().cpu().numpy()\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44662309-d77e-47eb-8e47-206981f690e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca7867-c517-4688-84d3-4be818921928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# create input matrix\n",
    "input_matrix = torch.randn(5, 5)\n",
    "\n",
    "# perform SVD\n",
    "u, s, v = torch.svd(input_matrix)\n",
    "\n",
    "# set all but the top k singular values to zero\n",
    "k = 2\n",
    "s[k:] = 0\n",
    "\n",
    "# reconstruct matrix\n",
    "output_matrix = torch.matmul(u, torch.matmul(torch.diag(s), v.t()))\n",
    "\n",
    "# print input and output matrices\n",
    "print(\"Input matrix:\\n\", input_matrix)\n",
    "print(\"Output matrix:\\n\", output_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376a034-9536-4206-9da3-f6adb397405a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1975ca75-d47c-48bb-8785-cb0e3b927563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Define the model architecture\n",
    "class LSFENet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Generate random input\n",
    "input_mat = torch.rand(10, 10)\n",
    "\n",
    "# Perform SVD\n",
    "U, S, V = torch.svd(input_mat)\n",
    "\n",
    "# Keep top k singular values\n",
    "k = 5\n",
    "S = torch.diag(S[:k])\n",
    "U = U[:, :k]\n",
    "V = V[:, :k]\n",
    "\n",
    "# Construct new matrix using U and V\n",
    "new_mat = U @ S @ V.t()\n",
    "\n",
    "# Apply LSFENet model to learn a new matrix\n",
    "model = LSFENet(input_dim=10, output_dim=10)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(new_mat)\n",
    "    loss = torch.norm(output - input_mat)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Output the result\n",
    "result = output.detach().numpy()\n",
    "print(result.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51ae19f-4701-42d8-b0f5-cac47359dd63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e752ddad-e572-494d-82e8-b25ebcec332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from geomloss import SamplesLoss\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define two matrices\n",
    "X = np.random.rand(10, 2)\n",
    "Y = np.random.rand(8, 2)\n",
    "\n",
    "# Calculate distance using geomloss\n",
    "loss = SamplesLoss(\"sinkhorn\", p=2, blur=0.1)\n",
    "gw_dist = loss(torch.Tensor(X), torch.Tensor(Y))\n",
    "\n",
    "# Calculate distance using torch.nn.CosineSimilarityLoss\n",
    "cosine_similarity_loss = nn.CosineSimilarity(dim=1)\n",
    "idx = np.random.choice(X.shape[0], size=Y.shape[0], replace=False)\n",
    "pm_dist = 1 - cosine_similarity_loss(torch.Tensor(X[idx]), torch.Tensor(Y))\n",
    "\n",
    "# Print the two matrices\n",
    "print(\"GeomLoss distance matrix:\")\n",
    "print(gw_dist.detach().numpy())\n",
    "\n",
    "print(\"PyTorch Metric Learning distance matrix:\")\n",
    "print(pm_dist.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a771c81-baa6-42d5-b4ab-552524b4b714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d73cfc-4263-4fc2-b220-bc94a7b9cbca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cfd78e-bd40-42a8-8409-2644dc8ca43f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5a94f8-066a-4b19-ae45-93077e5493c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91833e0-053f-4a01-b66c-d51302af327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ot\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def matrix_factorization(X, k, lmbda, alpha, beta, num_iterations):\n",
    "    # Compute SVD\n",
    "    U, s, Vt = svds(X, k)\n",
    "    S = np.diag(s)\n",
    "    # Initialize low-rank matrix Z\n",
    "    Z = U @ S @ Vt\n",
    "    # Compute pairwise distance matrices\n",
    "    D1 = pairwise_distances(X, metric='euclidean')\n",
    "    D2 = pairwise_distances(Z, metric='euclidean')\n",
    "    # Compute lifted embeddings\n",
    "    C1 = np.exp(-alpha * D1)\n",
    "    C2 = np.exp(-beta * D2)\n",
    "    # Compute optimal transport plan\n",
    "    P = ot.gromov.entropic_gromov_wasserstein(C1, C2, np.ones(X.shape[0])/X.shape[0], np.ones(Z.shape[0])/Z.shape[0], 'square_loss', epsilon=1e-2)\n",
    "    # Update Z using optimal transport plan\n",
    "    Z = P @ X\n",
    "    # Compute SVD of Z\n",
    "    U, s, Vt = svds(Z, k)\n",
    "    S = np.diag(s)\n",
    "    # Compute loss\n",
    "    loss = np.linalg.norm(X - U @ S @ Vt) ** 2\n",
    "    # Regularization\n",
    "    reg_loss = lmbda * np.sum(np.abs(U)) + lmbda * np.sum(np.abs(Vt))\n",
    "    # Compute final objective\n",
    "    obj = loss + reg_loss\n",
    "    # Iteratively update Z and compute objective\n",
    "    for i in range(num_iterations):\n",
    "        # Compute pairwise distance matrices\n",
    "        D1 = pairwise_distances(X, metric='euclidean')\n",
    "        D2 = pairwise_distances(Z, metric='euclidean')\n",
    "        # Compute lifted embeddings\n",
    "        C1 = np.exp(-alpha * D1)\n",
    "        C2 = np.exp(-beta * D2)\n",
    "        # Compute optimal transport plan\n",
    "        P = ot.gromov.entropic_gromov_wasserstein(C1, C2, np.ones(X.shape[0])/X.shape[0], np.ones(Z.shape[0])/Z.shape[0], 'square_loss', epsilon=1e-2)\n",
    "        # Update Z using optimal transport plan\n",
    "        Z = P @ X\n",
    "        # Compute SVD of Z\n",
    "        U, s, Vt = svds(Z, k)\n",
    "        S = np.diag(s)\n",
    "        # Compute loss\n",
    "        loss = np.linalg.norm(X - U @ S @ Vt) ** 2\n",
    "        # Regularization\n",
    "        reg_loss = lmbda * np.sum(np.abs(U)) + lmbda * np.sum(np.abs(Vt))\n",
    "        # Compute final objective\n",
    "        obj = loss + reg_loss\n",
    "        if i % 10 == 0:\n",
    "            print('Iteration:', i, 'Objective:', obj)\n",
    "    return U, S, Vt\n",
    "\n",
    "def main():\n",
    "    # Generate random data\n",
    "    X = np.random.rand(30, 10)\n",
    "    # Set parameters\n",
    "    k = 5\n",
    "    lmbda = 0.01\n",
    "    alpha = 0.1\n",
    "    beta = 0.1\n",
    "    num_iterations = 100\n",
    "    # Run matrix factorization\n",
    "    U, S, Vt = matrix_factorization(X, k, lmbda, alpha, beta, num_iterations)\n",
    "    # Print results\n",
    "    print(U.shape)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5f5036-cbcb-47c5-b525-0021259dbbb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8529fc-1749-4aa2-aa4b-17339bf67c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72712e9c-a219-4d7f-a3f7-5bde15c61e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26e1ef8-51cc-4ad2-b45d-a1fe07760bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from itertools import combinations\n",
    "\n",
    "num_embeddings = 10\n",
    "embed_dim = 16\n",
    "\n",
    "# generate random embeddings\n",
    "embeddings = torch.randn(num_embeddings, embed_dim)\n",
    "\n",
    "# generate all possible pairs of embeddings\n",
    "pairs = list(combinations(range(num_embeddings), 2))\n",
    "\n",
    "# generate corresponding labels for each pair\n",
    "labels = torch.randint(high=2, size=(len(pairs),))\n",
    "\n",
    "# create a DataLoader to iterate over the pairs and labels during training\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "dataset = TensorDataset(torch.tensor(pairs), labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aab6c7-41f6-4110-857b-4177a3fac8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_rank_loss(embeddings, triplets, margin=0.1):\n",
    "    anchor, positive, negative = triplets[:, 0], triplets[:, 1], triplets[:, 2]\n",
    "    ap_dist = torch.norm(embeddings[anchor] - embeddings[positive], p=2, dim=1)\n",
    "    an_dist = torch.norm(embeddings[anchor] - embeddings[negative], p=2, dim=1)\n",
    "    loss = torch.nn.functional.relu(ap_dist - an_dist + margin)\n",
    "    rank_penalty = rank_loss(embeddings)\n",
    "    return torch.mean(loss) + rank_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb22fbf6-5a87-4b50-bfb3-b0d64f3d2a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from geomloss import SamplesLoss\n",
    "\n",
    "def gromov_wasserstein_rank_loss(x, lam, p=2, q=2, epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Minimize D(C,M) +  * R(M), where D is the Gromov-Wasserstein distance function,\n",
    "    C is the cost matrix, M is the coupling matrix,  is a regularization parameter,\n",
    "    and R is the rank-preserving regularization term.\n",
    "    \"\"\"\n",
    "    # initialize random coupling matrix M\n",
    "    M = torch.rand(x.shape[0], x.shape[1])\n",
    "    M = M / M.sum()\n",
    "\n",
    "    # define cost matrix C\n",
    "    C = torch.abs(x.unsqueeze(0) - x.unsqueeze(1))\n",
    "    C /= C.max()\n",
    "\n",
    "    # define rank-preserving regularization term\n",
    "    def rank_loss(M):\n",
    "        u, s, v = torch.svd(M)\n",
    "        s = torch.nn.functional.softplus(s)\n",
    "        M_rank = u @ torch.diag(s) @ v.t()\n",
    "        return ((M - M_rank)**2).sum()\n",
    "\n",
    "    # define loss function\n",
    "    def loss_fn(M):\n",
    "        samples_loss = SamplesLoss(\"sinkhorn\", p=p, blur=epsilon, scaling=0.95, backend=\"tensorized\")\n",
    "        return samples_loss(C, M) + lam * rank_loss(M)\n",
    "\n",
    "    # set optimization parameters\n",
    "    lr = 0.01\n",
    "    momentum = 0.9\n",
    "    nesterov = True\n",
    "    weight_decay = 1e-4\n",
    "    epochs = 1000\n",
    "\n",
    "    # set optimizer\n",
    "    optimizer = torch.optim.SGD([M], lr=lr, momentum=momentum, nesterov=nesterov, weight_decay=weight_decay)\n",
    "\n",
    "    # train model\n",
    "    for epoch in range(epochs):\n",
    "        # compute loss\n",
    "        loss = loss_fn(M)\n",
    "        \n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backpropagate and update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # return final coupling matrix M\n",
    "    return M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55c11f0-eff9-4145-b784-083ca9adf23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095027ed-20b3-445f-8802-7fc5bf625269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_loss(embeddings):\n",
    "    U, s, V = torch.svd(embeddings)\n",
    "    rank_penalty = torch.norm(s, p=1)\n",
    "    return rank_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5e207a-3a50-4621-b2df-bb53a338c59a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0661fa6-57ba-405e-8f33-315c4ea62534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e635d3-5446-4164-a3e3-c2a8f5fedb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89be6e96-374e-4e11-b723-b894405d7f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f53edde-9c62-472c-b1cb-1d3dfe8adba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import ot\n",
    "\n",
    "# Define functions for computing pairwise similarity matrix and rank-preserving regularization term\n",
    "def compute_similarity_matrix(x):\n",
    "    C = torch.cdist(x, x)\n",
    "    C /= C.max()\n",
    "    return C\n",
    "\n",
    "def rank_regularization_term(M):\n",
    "    _, s, _ = torch.svd(M)\n",
    "    rank_loss = (1 - s / s[0]).sum()\n",
    "    return rank_loss\n",
    "\n",
    "# Define the loss function to be minimized\n",
    "def combined_loss(x, lambda_reg):\n",
    "    # Compute pairwise similarities using Gaussian kernel\n",
    "    C = compute_similarity_matrix(x)\n",
    "    # Compute Gromov-Wasserstein distance\n",
    "    M = ot.gromov.entropic_gromov_wasserstein(C, C, 'square_loss', epsilon=1e-4)\n",
    "    M = torch.tensor(M)\n",
    "\n",
    "    # Compute losses from papers\n",
    "    spectral_loss = spectral_loss_func(x)\n",
    "    lifted_struct_loss = lifted_struct_loss_func(x, y, M)\n",
    "\n",
    "    # Compute combined loss\n",
    "    gromov_wasserstein_loss = torch.norm(C - M, p='fro')\n",
    "    rank_loss = rank_regularization_term(M)\n",
    "    total_loss = gromov_wasserstein_loss + lambda_reg * rank_loss + spectral_loss + lifted_struct_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "# Initialize input tensor\n",
    "x = torch.randn(5, 5)\n",
    "\n",
    "# Set regularization parameter\n",
    "lambda_reg = 0.1\n",
    "\n",
    "# # Optimize for the output tensor\n",
    "# x_recon = x.clone().requires_grad_(True)\n",
    "# optimizer = torch.optim.Adam([x_recon], lr=0.01)\n",
    "# num_steps = 1000\n",
    "# for i in range(num_steps):\n",
    "#     optimizer.zero_grad()\n",
    "#     combined_loss_val = combined_loss(x_recon, lambda_reg)\n",
    "#     combined_loss_val.backward()\n",
    "#     optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43350116-4baa-4f2f-bcb5-580e4c137a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0df0d4-bc83-4078-909f-15fea7b69252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8dc89c-33d0-43ba-9298-63571b5ea850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d48dc-f137-4af0-9be7-92aca3c465e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# import ot\n",
    "\n",
    "# # Define the lifted structured feature embedding loss function\n",
    "# def lifted_struct_loss(x, y, M):\n",
    "#     n = x.shape[0]\n",
    "#     l = 0\n",
    "#     for i in range(n):\n",
    "#         for j in range(i + 1, n):\n",
    "#             if y[i] == y[j]:\n",
    "#                 Sij = 1\n",
    "#             else:\n",
    "#                 Sij = -1\n",
    "#             xi = x[i, :]\n",
    "#             xj = x[j, :]\n",
    "#             Mij = M[i, j]\n",
    "#             l += (Mij - torch.dot(xi - xj, xi - xj) * Sij) ** 2\n",
    "#     return l\n",
    "\n",
    "# # Define the direct metric learning loss function\n",
    "# def direct_metric_loss(x, M):\n",
    "#     n = x.shape[0]\n",
    "#     l = 0\n",
    "#     for i in range(n):\n",
    "#         for j in range(i + 1, n):\n",
    "#             xi = x[i, :]\n",
    "#             xj = x[j, :]\n",
    "#             Mij = M[i, j]\n",
    "#             l += (Mij - torch.dot(xi - xj, xi - xj)) ** 2\n",
    "#     return l\n",
    "\n",
    "# # Set random seed\n",
    "# torch.manual_seed(0)\n",
    "\n",
    "# # Generate random input matrix\n",
    "# x = torch.randn(5, 5)\n",
    "\n",
    "# # Compute pairwise similarities using entropic Gromov-Wasserstein distance\n",
    "# C = torch.abs(x.unsqueeze(0) - x.unsqueeze(1))\n",
    "# C /= C.max()\n",
    "# M = ot.gromov.entropic_gromov_wasserstein(C, C, 'square_loss', epsilon=1e-4)\n",
    "\n",
    "# # Compute lifted structured feature embedding loss\n",
    "# y = torch.randint(0, 2, (5,))\n",
    "# lifted_struct_loss_val = lifted_struct_loss(x, y, M)\n",
    "\n",
    "# # Compute direct metric learning loss\n",
    "# direct_metric_loss_val = direct_metric_loss(x, M)\n",
    "\n",
    "# # Set regularization parameter\n",
    "# lambda_val = 0.1\n",
    "\n",
    "# # Compute combined loss\n",
    "# combined_loss = lifted_struct_loss_val + lambda_val * direct_metric_loss_val\n",
    "\n",
    "# # Optimize for the output matrix\n",
    "# x_recon = x.clone().requires_grad_(True)\n",
    "# optimizer = torch.optim.Adam([x_recon], lr=0.01)\n",
    "# num_steps = 1000\n",
    "# for i in range(num_steps):\n",
    "#     optimizer.zero_grad()\n",
    "#     combined_loss_val = combined_loss(x_recon)\n",
    "#     combined_loss_val.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# # Print the output matrix\n",
    "# print(x_recon.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f87befd-1583-42f9-b0a9-ba3ec3efe80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd027eb-ce0e-484f-80fa-a246774c5551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import ot\n",
    "\n",
    "def lifted_struct_loss(x, y, M):\n",
    "    \"\"\"\n",
    "    Lifted structured feature embedding loss.\n",
    "    \"\"\"\n",
    "    # compute pairwise similarities between lifted feature vectors\n",
    "    S = x.mm(x.t())\n",
    "\n",
    "    # compute loss based on similarities between positive and negative pairs\n",
    "    num = y.shape[0]\n",
    "    pos_mask = y.expand(num, num).eq(y.expand(num, num).t())\n",
    "    neg_mask = ~pos_mask\n",
    "    pos_pairs = S[pos_mask].view(num, -1)\n",
    "    neg_pairs = S[neg_mask].view(num, -1)\n",
    "    diff = 1 - pos_pairs.unsqueeze(2) + neg_pairs.unsqueeze(1)\n",
    "    loss = torch.mean(torch.clamp(diff, min=0))\n",
    "\n",
    "    return loss\n",
    "\n",
    "def gromov_wasserstein_loss(x, y, C):\n",
    "    \"\"\"\n",
    "    Gromov-Wasserstein loss.\n",
    "    \"\"\"\n",
    "    # compute pairwise distances using cost matrix C\n",
    "    D_x = torch.cdist(x, x)\n",
    "    D_y = torch.cdist(y, y)\n",
    "\n",
    "    # compute Gromov-Wasserstein distance\n",
    "    M = ot.gromov.entropic_gromov_wasserstein(D_x, D_y, 'square_loss', epsilon=1e-4)\n",
    "    loss = ot.gromov.gromov_wasserstein(C, M)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def direct_loss(x, y, C):\n",
    "    \"\"\"\n",
    "    Direct loss.\n",
    "    \"\"\"\n",
    "    # compute pairwise distances using cost matrix C\n",
    "    D_x = torch.cdist(x, x)\n",
    "    D_y = torch.cdist(y, y)\n",
    "\n",
    "    # compute Direct distance\n",
    "    M = D_x - D_y\n",
    "    loss = torch.mean(torch.clamp(M, min=0)) + torch.mean(torch.clamp(-M, min=0))\n",
    "\n",
    "    return loss\n",
    "\n",
    "def rank_loss(x):\n",
    "    \"\"\"\n",
    "    Rank-preserving regularization term.\n",
    "    \"\"\"\n",
    "    _, s, _ = torch.svd(x)\n",
    "    r = torch.sum(torch.clamp(s, min=0.01))  # truncate singular values\n",
    "    return r\n",
    "\n",
    "def main():\n",
    "    # set random seed\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # generate random input matrix\n",
    "    x = torch.randn(5, 5)\n",
    "\n",
    "    # compute pairwise similarities using lifted structured feature embedding\n",
    "    lifted_struct_loss_val = 0.1\n",
    "    y = torch.randint(0, 2, (5,))\n",
    "    for i in range(10):\n",
    "        x_recon = x.clone().requires_grad_(True)\n",
    "        optimizer = optim.Adam([x_recon], lr=0.01)\n",
    "        num_steps = 1000\n",
    "        for j in range(num_steps):\n",
    "            optimizer.zero_grad()\n",
    "            lifted_struct_loss_val = lifted_struct_loss(x_recon, y, None)\n",
    "            lifted_struct_loss_val.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        x = x_recon.detach()\n",
    "\n",
    "    # compute pairwise similarities using Direct distance\n",
    "    direct_loss_val = 0.1\n",
    "    for i in range(10):\n",
    "        y = torch.randn(5, 5)\n",
    "        x_recon = x.clone().requires_grad_(True)\n",
    "        optimizer = optim.Adam([x_recon], lr=0.01)\n",
    "        num_steps = 1000\n",
    "        for j in range(num_steps):\n",
    "            optimizer.zero_grad()\n",
    "            direct_loss_val = direct_loss(x_recon, y, None)\n",
    "            direct_loss_val.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        x = x_recon.detach()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67e4c8-130b-4595-a629-9ad26ebf698b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c98aa9-c50a-4bc5-b936-f2d29b3239ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897b0e4-d4b5-40ba-a876-a670ee849a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cdaadf-d873-4206-af4c-e9fc5026f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import ot\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def lifted_struct_loss(x, y, margin=1.):\n",
    "    \"\"\"\n",
    "    Compute lifted structured loss.\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    dist = euclidean_distances(x, y)\n",
    "    loss = 0.\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                continue\n",
    "            diff = margin - dist[i, j] + dist[i, i]\n",
    "            if diff > 0:\n",
    "                loss += diff\n",
    "    return loss\n",
    "\n",
    "\n",
    "def rank_loss(x, y, lmbda=0.1):\n",
    "    \"\"\"\n",
    "    Compute rank loss.\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    diff = x - y\n",
    "    u, s, v = torch.svd(diff)\n",
    "    s = torch.clamp(s - lmbda, min=0)\n",
    "    rank = torch.sum(s > 0).item()\n",
    "    if rank == 0:\n",
    "        return 0.\n",
    "    return torch.norm(torch.matmul(torch.matmul(u, torch.diag(s)), v.T), p='fro') / rank\n",
    "\n",
    "\n",
    "def optimize_C(C1, C2, p, q, epsilon=1e-2, max_iter=1000, tol=1e-9):\n",
    "    \"\"\"\n",
    "    Optimize C1 and C2 using entropic Gromov-Wasserstein distance.\n",
    "    \"\"\"\n",
    "    n = C1.shape[0]\n",
    "    M = ot.utils.euclidean_distances(np.arange(n)[:, None], np.arange(n)[:, None])\n",
    "    loss_fun = 'square_loss'\n",
    "    reg = 1e-3\n",
    "\n",
    "    def objective(x):\n",
    "        M = x.reshape(n, n)\n",
    "        gw_loss = ot.gromov.entropic_gromov_wasserstein(C1, C2, p, q, loss_fun, epsilon, M=M, log=False, verbose=False, reg=reg)\n",
    "        lsf_loss = lifted_struct_loss(C1, C2)\n",
    "        rank_reg = rank_loss(C1, C2)\n",
    "        return gw_loss + 0.1 * lsf_loss + 0.1 * rank_reg\n",
    "\n",
    "    x0 = np.zeros((n ** 2,))\n",
    "    res = minimize(objective, x0, method='L-BFGS-B', jac=False, options={'maxiter': max_iter, 'tol': tol})\n",
    "    M_opt = res.x.reshape(n, n)\n",
    "    gw_loss_opt = ot.gromov.entropic_gromov_wasserstein(C1, C2, p, q, loss_fun, epsilon, M=M_opt, log=False, verbose=False, reg=reg)\n",
    "    C1_opt = torch.matmul(C1, torch.from_numpy(M_opt).float())\n",
    "    C2_opt = torch.matmul(C2, torch.from_numpy(M_opt).float())\n",
    "    rank_reg_opt = rank_loss(C1_opt, C2_opt)\n",
    "    print('Optimization complete. Gromov-Wasserstein loss: {:.4f}, Lifted Structured loss: {:.4f}, Rank loss: {:.4f}'.format(gw_loss_opt, lifted_struct_loss(C1_opt, C2_opt), rank_reg_opt))\n",
    "    return C1_opt, C2_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f57033-f770-401f-b1a5-18360d491269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944e4fd7-a6a3-43c6-b55d-50592d6cc451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import ot\n",
    "\n",
    "# Define the lifted structured feature embedding loss function\n",
    "def lifted_struct_loss(x, y, M):\n",
    "    n = x.shape[0]\n",
    "    l = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if y[i] == y[j]:\n",
    "                Sij = 1\n",
    "            else:\n",
    "                Sij = -1\n",
    "            xi = x[i, :]\n",
    "            xj = x[j, :]\n",
    "            Mij = M[i, j]\n",
    "            l += (Mij - torch.dot(xi - xj, xi - xj) * Sij) ** 2\n",
    "    return l\n",
    "\n",
    "# Define the direct metric learning loss function\n",
    "def direct_metric_loss(x, M):\n",
    "    n = x.shape[0]\n",
    "    l = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            xi = x[i, :]\n",
    "            xj = x[j, :]\n",
    "            Mij = M[i, j]\n",
    "            l += (Mij - torch.dot(xi - xj, xi - xj)) ** 2\n",
    "    return l\n",
    "\n",
    "# # Set random seed\n",
    "# torch.manual_seed(0)\n",
    "\n",
    "# # Generate random input matrix\n",
    "# x = torch.randn(5, 5)\n",
    "\n",
    "# # Compute pairwise similarities using entropic Gromov-Wasserstein distance\n",
    "# C = torch.abs(x.unsqueeze(0) - x.unsqueeze(1))\n",
    "# C /= C.max()\n",
    "# M = ot.gromov.entropic_gromov_wasserstein(C, C, 'square_loss', epsilon=1e-4)\n",
    "\n",
    "# # Compute lifted structured feature embedding loss\n",
    "# y = torch.randint(0, 2, (5,))\n",
    "# lifted_struct_loss_val = lifted_struct_loss(x, y, M)\n",
    "\n",
    "# # Compute direct metric learning loss\n",
    "# direct_metric_loss_val = direct_metric_loss(x, M)\n",
    "\n",
    "# # Set regularization parameter\n",
    "# lambda_val = 0.1\n",
    "\n",
    "# # Compute combined loss\n",
    "# combined_loss = lifted_struct_loss_val + lambda_val * direct_metric_loss_val\n",
    "\n",
    "# # Optimize for the output matrix\n",
    "# x_recon = x.clone().requires_grad_(True)\n",
    "# optimizer = torch.optim.Adam([x_recon], lr=0.01)\n",
    "# num_steps = 1000\n",
    "# for i in range(num_steps):\n",
    "#     optimizer.zero_grad()\n",
    "#     combined_loss_val = combined_loss(x_recon)\n",
    "#     combined_loss_val.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# # Print the output matrix\n",
    "# print(x_recon.detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b43905-007e-4a29-94a7-050c6f25de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from geomloss import SamplesLoss\n",
    "\n",
    "def gromov_wasserstein_rank_loss(C1, C2, lam=0.1, p=2, q=2, epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Minimize D(C,M) +  * L(C) +  * R(M), where D is the Gromov-Wasserstein distance function,\n",
    "    C is the cost matrix, M is the coupling matrix,  and  are regularization parameters,\n",
    "    L is the lifted structure loss, and R is the rank-preserving regularization term.\n",
    "    \"\"\"\n",
    "    # compute pairwise distances between the rows of C1 and C2\n",
    "    C1_norm = torch.norm(C1, dim=1, keepdim=True)\n",
    "    C2_norm = torch.norm(C2, dim=1, keepdim=True)\n",
    "    pairwise_distances = torch.cdist(C1/C1_norm, C2/C2_norm, p=2)\n",
    "\n",
    "    # compute Gromov-Wasserstein distance between the pairwise distances\n",
    "    gromov_wasserstein_loss = entropic_gromov_wasserstein(pairwise_distances, pairwise_distances, p, q, loss_fun=None, epsilon=epsilon,\n",
    "                                max_iter=1000, tol=1e-9, verbose=False, log=False)\n",
    "\n",
    "    # compute Lifted Structure Loss between the rows of C1 and C2\n",
    "    lifted_structure_loss = lifted_struct_loss(pairwise_distances)\n",
    "\n",
    "    # initialize random coupling matrix M\n",
    "    M = torch.rand(C1.shape[0], C2.shape[0])\n",
    "    M = M / M.sum()\n",
    "\n",
    "    # define rank-preserving regularization term\n",
    "    def rank_loss(M):\n",
    "        identity = torch.eye(C1.shape[0], C2.shape[0])\n",
    "        return ((M - identity)**2).sum()\n",
    "\n",
    "    # define loss function\n",
    "    def loss_fn(M):\n",
    "        samples_loss = SamplesLoss(\"sinkhorn\", p=p, q=q, blur=epsilon, scaling=0.95, backend=\"tensorized\")\n",
    "        return gromov_wasserstein_loss + lam * lifted_structure_loss + rank_loss(M)\n",
    "\n",
    "    # set optimization parameters\n",
    "    lr = 0.01\n",
    "    momentum = 0.9\n",
    "    nesterov = True\n",
    "    weight_decay = 1e-4\n",
    "    epochs = 1000\n",
    "\n",
    "    # set optimizer\n",
    "    optimizer = torch.optim.SGD([M], lr=lr, momentum=momentum, nesterov=nesterov, weight_decay=weight_decay)\n",
    "\n",
    "    # train model\n",
    "    for epoch in range(epochs):\n",
    "        # compute loss\n",
    "        loss = loss_fn(M)\n",
    "        \n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backpropagate and update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # return final coupling matrix M\n",
    "    return M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c9c2d8-2194-4dd0-b120-2f2c913d85d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.optim as optim\n",
    "# import ot\n",
    "\n",
    "# # define input matrices\n",
    "# C1 = torch.randn(5, 6)\n",
    "# C2 = torch.randn(10, 12)\n",
    "\n",
    "# # define regularization parameter\n",
    "# lam = 0.1\n",
    "\n",
    "# # define rank-preserving regularization term\n",
    "# def rank_loss(M):\n",
    "#     u, s, v = torch.svd(M)\n",
    "#     s = torch.nn.functional.softplus(s)\n",
    "#     M_rank = u @ torch.diag(s) @ v.t()\n",
    "#     return ((M - M_rank)**2).sum()\n",
    "\n",
    "# # define loss function\n",
    "# def loss_fn(C1, C2):\n",
    "#     p = ot.unif(C1.shape[0])\n",
    "#     p = torch.tensor(p)\n",
    "#     q = ot.unif(C2.shape[0])\n",
    "#     q = torch.tensor(q)\n",
    "#     samples_loss = ot.gromov.entropic_gromov_wasserstein(C1, C2, p, q, loss_fun='square_loss', epsilon=1e-3)\n",
    "#     return samples_loss\n",
    "#     return samples_loss + lam * rank_loss(M)\n",
    "\n",
    "# # initialize random coupling matrix M\n",
    "# M = torch.rand(C1.shape[0], C2.shape[0])\n",
    "# M = M / M.sum()\n",
    "\n",
    "# # set optimization parameters\n",
    "# lr = 0.01\n",
    "# momentum = 0.9\n",
    "# nesterov = True\n",
    "# weight_decay = 1e-4\n",
    "# epochs = 1000\n",
    "\n",
    "# # set optimizer\n",
    "# optimizer = optim.SGD([M], lr=lr, momentum=momentum, nesterov=nesterov, weight_decay=weight_decay)\n",
    "\n",
    "# # train model\n",
    "# for epoch in range(epochs):\n",
    "#     # compute loss\n",
    "    \n",
    "#     loss = loss_fn(C1, C2)\n",
    "    \n",
    "#     # zero gradients\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     # backpropagate and update\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# # return final coupling matrix M\n",
    "# print(M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d351876-56b2-4b85-8240-5c43c7ae2d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e76c51-0429-47ed-abae-1415ec019992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import ot\n",
    "\n",
    "# # Input cost matrices C1 and C2\n",
    "# C1 = torch.randn(5,5)\n",
    "# C2 = torch.randn(5,5)\n",
    "\n",
    "# # Define the parameters for the Gromov-Wasserstein distance computation\n",
    "# p = ot.unif(5)\n",
    "# p = torch.tensor(p)\n",
    "# q = ot.unif(5)\n",
    "# q = torch.tensor(q)\n",
    "# loss_fun = 'square_loss'\n",
    "# epsilon = 0.1\n",
    "# max_iter = 1000\n",
    "# tol = 1e-09\n",
    "# verbose = False\n",
    "# log = False\n",
    "\n",
    "# # Define the number of iterations for alternating minimization\n",
    "# num_iterations = 10\n",
    "\n",
    "# # Compute the initial Gromov-Wasserstein distance between C1 and C2\n",
    "# gw_dist = ot.gromov.entropic_gromov_wasserstein(C1, C2, p, q, loss_fun, epsilon, max_iter, tol, verbose, log)\n",
    "\n",
    "# # Perform alternating minimization to minimize the difference between C1 and C2 in terms of rank and Gromov-Wasserstein distance\n",
    "# for i in range(num_iterations):\n",
    "#     # Compute the rank of the difference between C1 and C2\n",
    "#     rank_diff = torch.matrix_rank(C1 - C2)\n",
    "#     # Compute the gradient of the Gromov-Wasserstein distance with respect to C1 and C2\n",
    "#     gw_grad1, gw_grad2 = ot.gromov.entropic_gromov_wasserstein2(C1, C2, p, q, loss_fun, epsilon, max_iter, tol, verbose, log)\n",
    "#     # Update C1 and C2 using the gradients and the rank of the difference\n",
    "#     C1 -= 0.01 * rank_diff * gw_grad1\n",
    "#     C2 -= 0.01 * rank_diff * gw_grad2\n",
    "#     # Compute the new Gromov-Wasserstein distance between the updated C1 and C2\n",
    "#     new_gw_dist = ot.gromov.entropic_gromov_wasserstein(C1, C2, p, q, loss_fun, epsilon, max_iter, tol, verbose, log)\n",
    "#     # Print the current iteration and the new Gromov-Wasserstein distance\n",
    "#     print('Iteration', i, 'GW distance', new_gw_dist)\n",
    "\n",
    "# # Compute the final rank of the difference between C1 and C2\n",
    "# final_rank_diff = torch.matrix_rank(C1 - C2)\n",
    "# # Compute the final Gromov-Wasserstein distance between C1 and C2\n",
    "# final_gw_dist = ot.gromov.entropic_gromov_wasserstein(C1, C2, p, q, loss_fun, epsilon, max_iter, tol, verbose, log)\n",
    "\n",
    "# # Print the final rank and Gromov-Wasserstein distance\n",
    "# print('Final rank difference', final_rank_diff)\n",
    "# print('Final GW distance', final_gw_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507c6cf1-d0e7-4ac1-b511-f9ae1572874f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25403610-e10a-48f1-a0dd-84b62e6f0eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd785ab3-2abe-414f-8308-34bc0782ca78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c93467-4079-4f2f-9f46-59dc11ccea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# from scipy.spatial.distance import pdist\n",
    "\n",
    "# def max_rank_matrix(X, k):\n",
    "#     U, S, V = torch.svd(X)\n",
    "#     S[k:] = 0\n",
    "#     return U @ torch.diag(S) @ V.t()\n",
    "\n",
    "# def pad_matrix(X, target_shape):\n",
    "#     X_padded = torch.zeros(target_shape)\n",
    "#     X_padded[:X.shape[0], :X.shape[1]] = X\n",
    "#     return X_padded\n",
    "\n",
    "# # Example inputs\n",
    "# C1 = torch.randn(5, 10)\n",
    "# C2 = torch.randn(8, 20)\n",
    "\n",
    "# # Find closest matrices in terms of rank\n",
    "# k1 = torch.linalg.matrix_rank(C1)\n",
    "# k2 = torch.linalg.matrix_rank(C2)\n",
    "# C1_closest_rank = max_rank_matrix(C1, k1)\n",
    "# C2_closest_rank = max_rank_matrix(C2, k2)\n",
    "\n",
    "# # Pad matrices to the same shape\n",
    "# target_shape = (max(C1.shape[0], C2.shape[0]), max(C1.shape[1], C2.shape[1]))\n",
    "# C1_tilda = pad_matrix(C1_closest_rank, target_shape)\n",
    "# C2_tilda = pad_matrix(C2_closest_rank, target_shape)\n",
    "\n",
    "# # Compute Gromov-Wasserstein distance\n",
    "# p = np.ones(C1_tilda.shape[0]) / C1_tilda.shape[0]\n",
    "# q = np.ones(C2_tilda.shape[0]) / C2_tilda.shape[0]\n",
    "# epsilon = 0.1\n",
    "# gw_distance = ot.gromov.entropic_gromov_wasserstein(C1_tilda, C2_tilda, p, q, 'square_loss', epsilon)\n",
    "\n",
    "# # Print results\n",
    "# print(\"C1_tilda:\\n\", C1_tilda)\n",
    "# print(\"C2_tilda:\\n\", C2_tilda)\n",
    "# print(\"Gromov-Wasserstein distance:\", gw_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ef127-0892-4648-9a72-ef2cdfc25051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6028e2-c114-42d2-9065-c61ca8a2b179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390a3f8-2707-471e-8a93-f36ee391576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# import ot\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "# import pytorch_metric_learning.losses as loss\n",
    "\n",
    "# def combined_loss(x, y, C1, C2, p, q, epsilon=1e-2, max_iter=1000, tol=1e-9):\n",
    "#     # compute lifted structure loss\n",
    "#     lifted_loss = loss.LiftedStructureLoss()(x, y)\n",
    "\n",
    "#     # compute SVD loss\n",
    "#     svd_loss_val = svd_loss(x)\n",
    "\n",
    "#     # compute entropic Gromov-Wasserstein loss\n",
    "#     C1 = torch.tensor(C1).float()\n",
    "#     C2 = torch.tensor(C2).float()\n",
    "#     M = ot.utils.dist(C1, C2)\n",
    "#     M /= M.max()\n",
    "#     p = torch.tensor(p).float()\n",
    "#     q = torch.tensor(q).float()\n",
    "#     egw_loss = ot.gromov.entropic_gromov_wasserstein(M, M, p, q, 'square_loss', epsilon=epsilon, max_iter=max_iter, tol=tol)\n",
    "\n",
    "#     # combine the losses\n",
    "#     combined_loss = lifted_loss + svd_loss_val + egw_loss\n",
    "\n",
    "#     return combined_loss\n",
    "\n",
    "# def main(num_iterations=10, batch_size=32, feature_dim=128, num_classes=10, num_samples=50, p=None, q=None):\n",
    "#     # set default values for p and q\n",
    "#     if p is None:\n",
    "#         p = np.ones(num_samples) / num_samples\n",
    "#     if q is None:\n",
    "#         q = np.ones(num_samples) / num_samples\n",
    "\n",
    "#     # find C1 and C2 with smallest combined_loss\n",
    "#     best_C1, best_C2 = None, None\n",
    "#     smallest_loss = float('inf')\n",
    "#     for i in range(num_iterations):\n",
    "#         # generate random input features and labels\n",
    "#         x = torch.randn(batch_size, feature_dim)\n",
    "#         y = torch.randint(num_classes, size=(batch_size,))\n",
    "\n",
    "#         # generate pairwise similarities\n",
    "#         C1 = np.random.rand(num_samples, num_samples)\n",
    "#         C2 = np.random.rand(num_samples, num_samples)\n",
    "\n",
    "#         # compute the loss\n",
    "#         loss_val = combined_loss(x, y, C1, C2, p, q, epsilon=1e-2, max_iter=1000, tol=1e-9)\n",
    "\n",
    "#         # update the best C1 and C2 if the current loss is smaller\n",
    "#         if loss_val < smallest_loss:\n",
    "#             smallest_loss = loss_val\n",
    "#             best_C1 = C1\n",
    "#             best_C2 = C2\n",
    "\n",
    "#     return best_C1, best_C2\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0463f6fd-42f9-44ed-9d24-59da7d5200d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953828c3-7b8b-4131-87ee-bc676b6e3bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def lifted_structure_loss(embeddings, margin=1.0, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Compute Lifted Structured Feature Embedding loss for unsupervised metric learning.\n",
    "\n",
    "    Args:\n",
    "    embeddings: A tensor of shape (batch_size, embedding_size) representing the embeddings.\n",
    "    margin: A float representing the margin for the loss.\n",
    "    alpha: A float representing the weighting parameter for the loss.\n",
    "\n",
    "    Returns:\n",
    "    loss: A float representing the loss.\n",
    "    \"\"\"\n",
    "    batch_size = embeddings.shape[0]\n",
    "    similarities = F.cosine_similarity(embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=2)\n",
    "    mask = ~torch.eye(batch_size, dtype=torch.bool)\n",
    "    positives = similarities[mask].view(batch_size, -1)\n",
    "    negatives = similarities[~mask].view(batch_size, -1)\n",
    "\n",
    "    # Compute the loss for each pair of embeddings\n",
    "    diff = margin - positives.unsqueeze(2) + negatives.unsqueeze(1)\n",
    "    max_diff = torch.clamp(diff, min=0.0)\n",
    "    loss = alpha * torch.mean(torch.sum(max_diff, dim=(1,2))) \n",
    "\n",
    "    return loss\n",
    "\n",
    "# generate random embeddings\n",
    "embeddings = torch.randn(5, 10)\n",
    "\n",
    "# compute the lifted structure loss\n",
    "loss = lifted_structure_loss(embeddings)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c76c355-f40c-41aa-852f-e4eb6e61a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def lifted_structure_loss(embeddings, margin=1.0, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Compute Lifted Structured Feature Embedding loss for unsupervised metric learning.\n",
    "\n",
    "    Args:\n",
    "    embeddings: A tensor of shape (batch_size, embedding_size) representing the embeddings.\n",
    "    margin: A float representing the margin for the loss.\n",
    "    alpha: A float representing the weighting parameter for the loss.\n",
    "\n",
    "    Returns:\n",
    "    loss: A float representing the loss.\n",
    "    \"\"\"\n",
    "    batch_size = embeddings.shape[0]\n",
    "    similarities = F.cosine_similarity(embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=2)\n",
    "    mask = ~torch.eye(batch_size, dtype=torch.bool)\n",
    "    positives = similarities[mask].view(batch_size, -1)\n",
    "    negatives = similarities[~mask].view(batch_size, -1)\n",
    "\n",
    "    # Compute the loss for each pair of embeddings\n",
    "    diff = margin - positives.unsqueeze(2) + negatives.unsqueeze(1)\n",
    "    max_diff = torch.clamp(diff, min=0.0)\n",
    "    loss = alpha * torch.mean(torch.sum(max_diff, dim=(1,2))) \n",
    "\n",
    "    return loss\n",
    "\n",
    "# Example usage with two matrices\n",
    "C1 = torch.randn(5, 10)\n",
    "C2 = torch.randn(6, 12)\n",
    "\n",
    "# Learn embeddings using autoencoder or other unsupervised learning method\n",
    "embeddings1 = torch.randn(C1.shape[0], 64, requires_grad=True)  # (batch_size, embedding_size)\n",
    "embeddings2 = torch.randn(C2.shape[0], 64, requires_grad=True)  # (batch_size, embedding_size)\n",
    "\n",
    "# Optimize embeddings using Lifted Structured Feature Embedding loss\n",
    "optimizer = torch.optim.SGD([embeddings1, embeddings2], lr=0.001)\n",
    "\n",
    "for i in range(1000):\n",
    "    loss = lifted_structure_loss(embeddings1, margin=1.0, alpha=1.0) + lifted_structure_loss(embeddings2, margin=1.0, alpha=1.0)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Output learned embeddings\n",
    "print(embeddings1.shape)\n",
    "print(embeddings2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503d91d4-81d9-456c-ab93-3d885843482b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3715cf79-ac40-4fc6-bf63-0b0b6bab7145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def lifted_structure_loss(embeddings, margin=1.0, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Compute Lifted Structured Feature Embedding loss for unsupervised metric learning.\n",
    "\n",
    "    Args:\n",
    "        embeddings: A tensor of shape (batch_size, embedding_size) representing the embeddings.\n",
    "        margin: A float representing the margin for the loss.\n",
    "        alpha: A float representing the weighting parameter for the loss.\n",
    "\n",
    "    Returns:\n",
    "        loss: A float representing the loss.\n",
    "    \"\"\"\n",
    "    batch_size = embeddings.shape[0]\n",
    "    similarities = F.cosine_similarity(embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=2)\n",
    "    mask = ~torch.eye(batch_size, dtype=torch.bool)\n",
    "    positives = similarities[mask].view(batch_size, -1)\n",
    "    negatives = similarities[~mask].view(batch_size, -1)\n",
    "\n",
    "    # Compute the loss for each pair of embeddings\n",
    "    diff = margin - positives.unsqueeze(2) + negatives.unsqueeze(1)\n",
    "    max_diff = torch.clamp(diff, min=0.0)\n",
    "    loss = alpha * torch.mean(torch.sum(max_diff, dim=(1, 2)))\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Example usage with two matrices\n",
    "C1 = torch.randn(5, 10)\n",
    "C2 = torch.randn(6, 12)\n",
    "\n",
    "# Learn embeddings using autoencoder or other unsupervised learning method\n",
    "embeddings1 = torch.randn(C1.shape[0], 64, requires_grad=True)  # (batch_size, embedding_size)\n",
    "embeddings2 = torch.randn(C2.shape[0], 64, requires_grad=True)  # (batch_size, embedding_size)\n",
    "\n",
    "# Optimize embeddings using Lifted Structured Feature Embedding loss\n",
    "optimizer = torch.optim.SGD([embeddings1, embeddings2], lr=0.001)\n",
    "\n",
    "min_loss = float('inf')\n",
    "min_embeddings1, min_embeddings2 = None, None\n",
    "\n",
    "for i in range(1000):\n",
    "    loss1 = lifted_structure_loss(embeddings1, margin=1.0, alpha=1.0)\n",
    "    loss2 = lifted_structure_loss(embeddings2, margin=1.0, alpha=1.0)\n",
    "    loss = loss1 + loss2\n",
    "    \n",
    "    if loss < min_loss:\n",
    "        min_loss = loss.item()\n",
    "        min_embeddings1 = embeddings1.clone()\n",
    "        min_embeddings2 = embeddings2.clone()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Output results\n",
    "print(f\"Minimum loss: {min_loss:.4f}\")\n",
    "print(\"Minimum embeddings for C1:\")\n",
    "print(min_embeddings1.shape)\n",
    "print(\"Minimum embeddings for C2:\")\n",
    "print(min_embeddings2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b6cc8a-05f8-4b9e-b50a-d120be45bfb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb11bf-c7cd-4fc3-91ca-b0f3cd2f728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import ot\n",
    "\n",
    "def lifted_structure_loss(embeddings, margin=1.0, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Compute Lifted Structured Feature Embedding loss for unsupervised metric learning.\n",
    "\n",
    "    Args:\n",
    "    embeddings: A tensor of shape (batch_size, embedding_size) representing the embeddings.\n",
    "    margin: A float representing the margin for the loss.\n",
    "    alpha: A float representing the weighting parameter for the loss.\n",
    "\n",
    "    Returns:\n",
    "    loss: A float representing the loss.\n",
    "    \"\"\"\n",
    "    batch_size = embeddings.shape[0]\n",
    "    similarities = F.cosine_similarity(embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=2)\n",
    "    mask = ~torch.eye(batch_size, dtype=torch.bool)\n",
    "    positives = similarities[mask].view(batch_size, -1)\n",
    "    negatives = similarities[~mask].view(batch_size, -1)\n",
    "\n",
    "    # Compute the loss for each pair of embeddings\n",
    "    diff = margin - positives.unsqueeze(2) + negatives.unsqueeze(1)\n",
    "    max_diff = torch.clamp(diff, min=0.0)\n",
    "    loss = alpha * torch.mean(torch.sum(max_diff, dim=(1,2))) \n",
    "\n",
    "    return loss\n",
    "\n",
    "def rank_based_loss(embeddings, margin=0.5):\n",
    "    \"\"\"\n",
    "    Compute the rank-based loss for unsupervised metric learning.\n",
    "\n",
    "    Args:\n",
    "    embeddings: A tensor of shape (batch_size, embedding_size) representing the embeddings.\n",
    "    margin: A float representing the margin for the loss.\n",
    "\n",
    "    Returns:\n",
    "    loss: A float representing the loss.\n",
    "    \"\"\"\n",
    "    batch_size = embeddings.shape[0]\n",
    "    pairwise_distances = torch.cdist(embeddings, embeddings, p=2)\n",
    "    target_distances = torch.argsort(pairwise_distances, dim=1)\n",
    "    diff = (target_distances - torch.arange(batch_size).unsqueeze(1).to(embeddings.device)) / batch_size\n",
    "    loss = torch.mean(torch.clamp(margin - diff, min=0.0))\n",
    "    return loss\n",
    "\n",
    "# Define the input matrices\n",
    "C1 = torch.randn(5, 10)\n",
    "C2 = torch.randn(6, 12)\n",
    "\n",
    "# Define the embedding size\n",
    "embedding_size = 64\n",
    "\n",
    "# Initialize the embeddings\n",
    "embeddings1 = torch.randn(C1.shape[0], embedding_size, requires_grad=True)\n",
    "embeddings2 = torch.randn(C2.shape[0], embedding_size, requires_grad=True)\n",
    "\n",
    "# Define the number of iterations\n",
    "num_iterations = 1000\n",
    "\n",
    "# Define the learning rate\n",
    "lr = 0.001\n",
    "\n",
    "# Define the margin and alpha parameters for the loss functions\n",
    "margin_ls = 1.0\n",
    "alpha_ls = 1.0\n",
    "margin_rb = 0.5\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.SGD([embeddings1, embeddings2], lr=lr)\n",
    "\n",
    "# Define the distance matrices\n",
    "D1 = torch.cdist(embeddings1, embeddings1, p=2)\n",
    "D2 = torch.cdist(embeddings2, embeddings2, p=2)\n",
    "\n",
    "# Define the regularization strength for the entropic regularization\n",
    "reg = 0.1\n",
    "\n",
    "# Run the optimization loop\n",
    "for i in range(num_iterations):\n",
    "    # Compute the losses\n",
    "    ls_loss = lifted_structure_loss(embeddings1, margin=margin_ls, alpha=alpha_ls) + lifted_structure_loss(embeddings2, margin=margin_ls, alpha=alpha_ls)\n",
    "    rb_loss = rank_based_loss(embeddings1, margin=margin_rb) + rank_based_loss(embeddings2, margin=margin_rb)\n",
    "    loss = ls_loss + rb_loss\n",
    "\n",
    "    # Update the embeddings\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Apply entropic regularization\n",
    "    p1 = F.softmax(-D1/reg, dim=1)\n",
    "    p2 = F.softmax(-D2/reg, dim=1)\n",
    "    new_embeddings1 = torch.matmul(p1, embeddings1)\n",
    "    new_embeddings2 = torch.matmul(p2, embeddings2)\n",
    "    embeddings1.data = new_embeddings1.data\n",
    "    embeddings2.data = new_embeddings2.data\n",
    "\n",
    "# Update the C1 and C2 matrices with the learned embeddings\n",
    "C1 = embeddings1.detach().numpy()\n",
    "C2 = embeddings2.detach().numpy()\n",
    "\n",
    "# Print the new C1 and C2 matrices\n",
    "print(\"New C1:\")\n",
    "print(C1.shape)\n",
    "print(\"New C2:\")\n",
    "print(C2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fac19f-ee3c-48c4-9d21-046da08a1078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e21a9d-615a-4d73-95ad-e91f1502dd04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f28ec9-83d0-4f2f-b349-6a93444a92cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32998e54-ca66-4837-a306-ed66af8105a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_metric_learning import losses, miners, distances, reducers, testers\n",
    "\n",
    "# Define the input matrices\n",
    "C1 = torch.randn(5, 10)\n",
    "C2 = torch.randn(6, 12)\n",
    "\n",
    "# Define the embedding size\n",
    "embedding_size = 64\n",
    "\n",
    "# Initialize the embeddings\n",
    "embeddings1 = torch.randn(C1.shape[0], embedding_size, requires_grad=True)\n",
    "embeddings2 = torch.randn(C2.shape[0], embedding_size, requires_grad=True)\n",
    "\n",
    "# Define the number of iterations\n",
    "num_iterations = 1000\n",
    "\n",
    "# Define the learning rate\n",
    "lr = 0.001\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.SGD([embeddings1, embeddings2], lr=lr)\n",
    "\n",
    "# Define the distance metric\n",
    "distance_metric = distances.CosineSimilarity()\n",
    "\n",
    "# Define the loss functions\n",
    "losses_list = [\n",
    "    losses.AngularLoss(),\n",
    "    losses.TripletMarginLoss(),\n",
    "    losses.NPairsLoss(),\n",
    "    losses.SoftTripleLoss(),\n",
    "    losses.ProxyNCALoss(),\n",
    "    losses.MultiSimilarityLoss(),\n",
    "    losses.MultiSimilarityMarginLoss(),\n",
    "    losses.NCA_Loss(),\n",
    "    losses.NCA_Loss_SuperviseWeights(),\n",
    "    losses.IntraPairVariancePenalizationLoss(),\n",
    "    losses.LiftedStructLoss(),\n",
    "    losses.ContrastiveLoss(),\n",
    "    losses.MultiSimilarityMultipleLoss(),\n",
    "    losses.CircleLoss(),\n",
    "    losses.MultiSimilarityTripletsLoss(),\n",
    "    losses.MutualEmbeddingLoss(),\n",
    "    losses.TupletMarginLoss(),\n",
    "    losses.CombinationLoss()\n",
    "]\n",
    "\n",
    "# Define the mining functions\n",
    "miner = miners.MultiSimilarityMiner(epsilon=0.1)\n",
    "\n",
    "# Define the reduction function\n",
    "reducer = reducers.MeanReducer()\n",
    "\n",
    "# Define the tester to calculate the loss and embeddings\n",
    "tester = testers.GlobalEmbeddingSpaceTester(\n",
    "    embeddings=[embeddings1, embeddings2],\n",
    "    dataloader=None,\n",
    "    recall_at=[1],\n",
    "    eval_splits=[\"test\"],\n",
    "    distance_metric=distance_metric,\n",
    "    reducer=reducer,\n",
    "    testing_kwargs={\"batch_size\": 32},\n",
    ")\n",
    "\n",
    "# Define the regularization strength for the entropic regularization\n",
    "reg = 0.1\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    # Compute the losses\n",
    "    loss_vals = [loss(embeddings1, embeddings2, labels=None, miner=miner, distance_metric=distance_metric) for loss in losses_list]\n",
    "    loss = torch.stack(loss_vals).mean()\n",
    "    \n",
    "    # Update the embeddings\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Apply entropic regularization\n",
    "    D1 = distance_metric(embeddings1, embeddings1)\n",
    "    D2 = distance_metric(embeddings2, embeddings2)\n",
    "    p1 = torch.softmax(-D1/reg, dim=1)\n",
    "    p2 = torch.softmax(-D2/reg, dim=1)\n",
    "    embeddings1 = torch.matmul(p1, embeddings1)\n",
    "    embeddings2 = torch.matmul(p2, embeddings2)\n",
    "\n",
    "# Compute the embeddings and loss\n",
    "test_results = tester.test()\n",
    "embeddings = test_results[\"embeddings\"]\n",
    "loss = test_results[\"recall_at_1\"][0]\n",
    "\n",
    "# Get the 2 matrices with the smallest loss\n",
    "C1_hat = embeddings[0].detach().numpy()\n",
    "C2_hat = embeddings[1].detach().numpy()\n",
    "\n",
    "# Print the matrices\n",
    "print(\"C1_hat:\", C1_hat)\n",
    "print(\"C2_hat:\", C2_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f873fb8-260e-42e9-bc30-5b76af87a884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affe3af7-5291-49cb-bd7a-32b9d60c80cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from pytorch_metric_learning import losses\n",
    "\n",
    "# # Define the input matrices\n",
    "# C1 = torch.randn(5, 10)\n",
    "# C2 = torch.randn(6, 12)\n",
    "\n",
    "# # Define the embedding size\n",
    "# embedding_size = 64\n",
    "\n",
    "# # Initialize the embeddings\n",
    "# embeddings1 = torch.randn(C1.shape[0], embedding_size, requires_grad=True)\n",
    "# embeddings2 = torch.randn(C2.shape[0], embedding_size, requires_grad=True)\n",
    "\n",
    "# # Define the number of iterations\n",
    "# num_iterations = 1000\n",
    "\n",
    "# # Define the learning rate\n",
    "# lr = 0.001\n",
    "\n",
    "# # Define the margin and alpha parameters for the loss functions\n",
    "# margin_ls = 1.0\n",
    "# alpha_ls = 1.0\n",
    "# margin_rb = 0.5\n",
    "# beta_a = 50.0\n",
    "# beta_b = 1.0\n",
    "# beta_c = 0.01\n",
    "\n",
    "# # Define the optimizer\n",
    "# optimizer = torch.optim.SGD([embeddings1, embeddings2], lr=lr)\n",
    "\n",
    "# # Define the distance metric\n",
    "# distance_metric = losses.CosineSimilarity()\n",
    "\n",
    "# # Define the loss functions\n",
    "# triplet_loss = losses.TripletMarginLoss(margin=margin_ls, distance_metric=distance_metric, type_of_triplets=\"all\", swap=False)\n",
    "# n_pairs_loss = losses.NPairsLoss(margin=margin_rb, distance_metric=distance_metric)\n",
    "# contrastive_loss = losses.ContrastiveLoss(margin=margin_ls, distance_metric=distance_metric)\n",
    "# lifted_struct_loss = losses.LiftedStructLoss(alpha=alpha_ls, margin=margin_ls, distance_metric=distance_metric)\n",
    "# angular_loss = losses.AngularLoss(scale=30.0, embedding_size=embedding_size)\n",
    "# circle_loss = losses.CircleLoss(m=0.25, gamma=80.0, distance_metric=distance_metric)\n",
    "# fast_ap_loss = losses.FastAPLoss(beta=beta_a, margin=margin_ls, distance_metric=distance_metric)\n",
    "# multi_similarity_loss = losses.MultiSimilarityLoss(alpha=alpha_ls, beta=beta_b, gamma=beta_c, distance_metric=distance_metric)\n",
    "# triplet_margin_soft_loss = losses.TripletMarginSoftMarginLoss(margin=margin_ls, distance_metric=distance_metric)\n",
    "\n",
    "# # Define the mining functions\n",
    "# lifted_miner = losses.MultiSimilarityMiner(epsilon=0.1)\n",
    "# n_pairs_miner = losses.HardNegativePairMiner()\n",
    "# contrastive_miner = losses.HardPairMiner()\n",
    "# lifted_struct_miner = losses.HardTripletsMiner()\n",
    "# fast_ap_miner = losses.HardTripletMiner()\n",
    "# multi_similarity_miner = losses.MultiSimilarityMiner(epsilon=0.1)\n",
    "\n",
    "# # Define the reduction function\n",
    "# reducer = losses.MeanReducer()\n",
    "\n",
    "# # Define the tester to calculate the loss and embeddings\n",
    "# tester = losses.GlobalEmbeddingSpaceTester(\n",
    "#     embeddings=[embeddings1, embeddings2],\n",
    "#     dataloader=None,\n",
    "#     recall_at=[1],\n",
    "#     eval_splits=[\"test\"],\n",
    "#     distance_metric=distance_metric,\n",
    "#     reducer=reducer,\n",
    "#     testing_kwargs={\"batch_size\": 32},\n",
    "# )\n",
    "\n",
    "# # Define the regularization strength for the entropic regularization\n",
    "# reg = 0.1\n",
    "\n",
    "# for i in range(num_iterations):\n",
    "#     # Compute the losses\n",
    "#     triplet_loss_val, _, _ = triplet_loss(embeddings1, embeddings2, labels=None, miner=lifted_miner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da390d14-7866-4042-973c-2c178acdbca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf461bc-3bfc-4070-9cb5-76f7f6b3a67c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c5bf3e-3b1c-45dc-bd44-7c0a77e05293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LiftedStructureLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(LiftedStructureLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        n, d = x1.size()\n",
    "        m, d = x2.size()\n",
    "\n",
    "        # Compute pairwise distance matrix\n",
    "        dist_mat = torch.pow(x1, 2).sum(dim=1, keepdim=True).expand(n, m) + \\\n",
    "            torch.pow(x2, 2).sum(dim=1, keepdim=True).expand(m, n).t()\n",
    "        dist_mat.addmm_(1, -2, x1, x2.t())\n",
    "\n",
    "        # Compute pairwise similarity matrix\n",
    "        sim_mat = torch.exp(-dist_mat)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = 0.0\n",
    "        num_pos_pairs = 0\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                pos_sim = sim_mat[i,j]\n",
    "                for k in range(m):\n",
    "                    if k == j:\n",
    "                        continue\n",
    "                    neg_sim = sim_mat[i,k]\n",
    "                    if neg_sim + self.margin > pos_sim:\n",
    "                        loss += neg_sim + self.margin - pos_sim\n",
    "                        num_pos_pairs += 1\n",
    "\n",
    "        if num_pos_pairs > 0:\n",
    "            loss /= num_pos_pairs\n",
    "        else:\n",
    "            loss = 0.0\n",
    "\n",
    "        return loss\n",
    "\n",
    "# Define input matrices C1 and C2\n",
    "C1 = torch.randn(5, 14)\n",
    "C2 = torch.randn(12, 14)\n",
    "\n",
    "# Define the Lifted Structure loss function with a margin of 1.0\n",
    "loss_fn = LiftedStructureLoss(margin=1.0)\n",
    "\n",
    "# Compute the loss\n",
    "loss = loss_fn(C1, C2)\n",
    "\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb327a-9db6-447f-96f8-b444a0fb8be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219dab28-bb92-4d20-9b6d-c93e5fa770a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define input matrices C1 and C2\n",
    "C1 = torch.randn(5, 14, requires_grad=True)\n",
    "C2 = torch.randn(12, 14, requires_grad=True)\n",
    "\n",
    "# Define the Lifted Structure loss function with a margin of 1.0\n",
    "loss_fn = LiftedStructureLoss(margin=1.0)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD([C1, C2], lr=0.01)\n",
    "\n",
    "# Perform SGD for 1000 iterations\n",
    "num_iters = 1000\n",
    "for i in range(num_iters):\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fn(C1, C2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 100 iterations\n",
    "    if i % 100 == 0:\n",
    "        print(\"Iteration {}: Loss = {:.4f}\".format(i, loss))\n",
    "\n",
    "# Print the final loss and output matrices\n",
    "print(\"Final loss:\", loss)\n",
    "print(\"C1:\", C1.shape)\n",
    "print(\"C2:\", C2.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7bee15-0f52-4743-b451-8a5800dad0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69030100-7eaa-4299-810b-db86a0f2685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FastAPLoss(nn.Module):\n",
    "    def __init__(self, beta=1.0, eps=1e-8):\n",
    "        super(FastAPLoss, self).__init__()\n",
    "        self.beta = beta\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, X):\n",
    "        n = X.size(0)\n",
    "        \n",
    "        # Compute pairwise similarities\n",
    "        sim_mat = torch.mm(X, X.t())\n",
    "        sim_mat = torch.exp(self.beta * sim_mat)\n",
    "        \n",
    "        # Compute the ground truth relevance scores\n",
    "        r = torch.zeros(n, device=X.device)\n",
    "        r[-1] = 1\n",
    "        \n",
    "        # Compute the precision-at-k scores\n",
    "        cum_prec = torch.zeros(n, device=X.device)\n",
    "        cum_prec[0] = r[0]\n",
    "        for i in range(1, n):\n",
    "            cum_prec[i] = cum_prec[i-1] + r[i]\n",
    "        cum_prec /= torch.arange(1, n+1, device=X.device)\n",
    "        \n",
    "        # Compute the FastAP loss\n",
    "        loss = 0.0\n",
    "        for i in range(n):\n",
    "            ap = 0.0\n",
    "            for j in range(n):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if sim_mat[i,j] > sim_mat[i,i]:\n",
    "                    ap += (cum_prec[j] - cum_prec[i-1]) / (j - i + 1)\n",
    "            loss += ap * r[i]\n",
    "        loss /= torch.sum(r)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "# Define input matrix X\n",
    "X = torch.randn(2, 10)\n",
    "\n",
    "# Define the FastAP loss function with beta=1.0\n",
    "loss_fn = FastAPLoss(beta=1.0)\n",
    "\n",
    "# Compute the loss\n",
    "loss = loss_fn(X)\n",
    "\n",
    "print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ef94d7-e8ff-474a-9c9b-248c9f4fc0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6493d7ef-bb96-423c-be22-21f4fc4d11d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FastAPLoss(nn.Module):\n",
    "    def __init__(self, eps=0.1, alpha=10):\n",
    "        super(FastAPLoss, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        n, d = x.size()\n",
    "\n",
    "        # Compute pairwise similarity matrix\n",
    "        sim_mat = x.mm(x.t())\n",
    "        sim_mat = torch.exp(-self.alpha * (sim_mat - torch.max(sim_mat)))\n",
    "\n",
    "        # Compute sorted indices\n",
    "        sorted_indices = torch.argsort(sim_mat, dim=1, descending=True)\n",
    "\n",
    "        # Compute FastAP scores\n",
    "        ap_scores = []\n",
    "        for i in range(n):\n",
    "            tp = 0.0\n",
    "            fp = 0.0\n",
    "            ap = 0.0\n",
    "            for j in range(n):\n",
    "                idx = sorted_indices[i, j]\n",
    "                if idx == i:\n",
    "                    tp += 1.0\n",
    "                    ap += tp / (j + 1.0)\n",
    "                else:\n",
    "                    fp += 1.0\n",
    "                    if fp / (n - j + tp) < self.eps:\n",
    "                        ap += tp / (j + 1.0)\n",
    "                    else:\n",
    "                        break\n",
    "            ap_scores.append(ap)\n",
    "        loss = 1.0 - torch.mean(torch.tensor(ap_scores))\n",
    "\n",
    "        return loss\n",
    "\n",
    "class LiftedStructureLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(LiftedStructureLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        n, d = x1.size()\n",
    "        m, d = x2.size()\n",
    "\n",
    "        # Compute pairwise distance matrix\n",
    "        dist_mat = torch.pow(x1, 2).sum(dim=1, keepdim=True).expand(n, m) + \\\n",
    "            torch.pow(x2, 2).sum(dim=1, keepdim=True).expand(m, n).t()\n",
    "        dist_mat.addmm_(1, -2, x1, x2.t())\n",
    "\n",
    "        # Compute pairwise similarity matrix\n",
    "        sim_mat = torch.exp(-dist_mat)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = 0.0\n",
    "        num_pos_pairs = 0\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                pos_sim = sim_mat[i,j]\n",
    "                for k in range(m):\n",
    "                    if k == j:\n",
    "                        continue\n",
    "                    neg_sim = sim_mat[i,k]\n",
    "                    if neg_sim + self.margin > pos_sim:\n",
    "                        loss += neg_sim + self.margin - pos_sim\n",
    "                        num_pos_pairs += 1\n",
    "\n",
    "        if num_pos_pairs > 0:\n",
    "            loss /= num_pos_pairs\n",
    "        else:\n",
    "            loss = 0.0\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "# Define input matrices C1 and C2\n",
    "C1 = torch.randn(5, 10, requires_grad=True)\n",
    "C2 = torch.randn(6, 10, requires_grad=True)\n",
    "\n",
    "# Define the FastAP loss function with eps=0.1 and alpha=10\n",
    "fastap_loss_fn = FastAPLoss(eps=0.1, alpha=10)\n",
    "\n",
    "# Define the Lifted Structure loss function with a margin of 1.0\n",
    "lifted_loss_fn = LiftedStructureLoss(margin=1.0)\n",
    "\n",
    "# Define the optimizer (e.g. SGD or Adam)\n",
    "optimizer = torch.optim.SGD([C1, C2], lr=0.1)\n",
    "num_epochs = 10\n",
    "# Train the model for a certain number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    # Compute the total loss\n",
    "    total_loss = fastap_loss_fn(C1) + lifted_loss_fn(C1, C2)\n",
    "    \n",
    "    # Compute the gradients\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    \n",
    "    # Update the matrices\n",
    "    optimizer.step()\n",
    "    \n",
    "# Print the resulting matrices with the smallest loss\n",
    "print(\"C1:\", C1.shape)\n",
    "print(\"C2:\", C2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4036de1-84b8-4e14-8ffd-06a2569c97e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8fda40-348f-4baa-9a9b-d8e6d4ab62c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d18103-e8c7-4874-9f2c-c893dca0aae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175b741e-aa4e-43f1-974c-498dba0aab97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84405f6-0edb-4510-bc32-864eff93a2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a45b4-fb0b-4e9f-a6e8-60579b7b67f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6f82b2-69fe-4e4a-8b9e-a0c894e84d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad52bf-1d74-4bbd-b8d3-074f0840be4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a074677d-0c03-44fe-8110-288d4d966573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ot\n",
    "\n",
    "# define the inputs\n",
    "C1 = torch.randn(5, 5)\n",
    "\n",
    "C2 = torch.randn(6, 6)\n",
    "p = np.ones(5) / 5\n",
    "q = np.ones(6) / 6\n",
    "epsilon = 1\n",
    "max_iter = 1000\n",
    "tol = 1e-9\n",
    "\n",
    "# define the loss function\n",
    "def loss_fun(x, y):\n",
    "    return np.sum((x - y) ** 2)\n",
    "\n",
    "# compute the entropic Gromov-Wasserstein distance\n",
    "gw_dist = ot.gromov.entropic_gromov_wasserstein(\n",
    "    C1.numpy(),\n",
    "    C2.numpy(),\n",
    "    p,\n",
    "    q,\n",
    "    loss_fun = \"square_loss\",\n",
    "    epsilon=epsilon,\n",
    "    max_iter=max_iter,\n",
    "    tol=tol,\n",
    "    verbose=False,\n",
    "    log=False,\n",
    ")\n",
    "\n",
    "# print the optimal C1, C2, and loss\n",
    "print(f\"Optimal loss: {gw_dist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543b2dd-4b13-49d7-b345-958a9209dc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4437e47-7154-4dbf-88b9-436e480b2b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf84ff3-da8a-4f6e-92ca-a528924ca2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d31fe9-8bde-4297-8d5e-c13675fbe9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef3dc57-47dd-454b-a144-0144cfdf3f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c586c31a-7f3b-4c19-b672-41340600fe5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59274154-af8c-43b7-a216-e60caa186454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be20ff9f-3ec1-4f4d-a20d-56b5304f4f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a3ea25-f53d-4aa9-94a0-56dc1a9fdaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e91118-34ba-4cd0-bd8f-804a20e708f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import metric_learn\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "\n",
    "# For optimal transport operations:\n",
    "import ot\n",
    "# For computing graph distances:\n",
    "from scipy.sparse.csgraph import dijkstra\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "# For pre-processing, normalization\n",
    "from sklearn.preprocessing import StandardScaler, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990db435-c4e6-405e-9329-0e4796794d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatac=np.load(\"../data/scatac_feat.npy\") \n",
    "scrna=np.load(\"../data/scrna_feat.npy\")\n",
    "print(\"Dimensions of input datasets are: \", \"X= \", scatac.shape, \" y= \", scrna.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48aa8c2-de09-4b33-9610-2d4372a8148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, X2  = normalize(scatac, norm=\"l2\"), normalize(scrna, norm=\"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8646da-4b6d-4efa-9562-1c2ca9141d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=np.loadtxt(\"../data/SNAREseq_atac_types.txt\")\n",
    "y2=np.loadtxt(\"../data/SNAREseq_rna_types.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241319b3-e52a-41d1-a7cf-82ed6b2faf43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77affa72-f3f3-48ee-a310-d5e4bdb02356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262ab08-94f1-48b5-ae24-6b2dee0ef205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c30e9d-394b-4b39-aed9-78a5d67f1e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calcCov(x, y):\n",
    "#     mean_x, mean_y = x.mean(), y.mean()\n",
    "#     n = len(x)\n",
    "#     return sum((x - mean_x) * (y - mean_y)) / n\n",
    "# def cov(data):\n",
    "#     rows, cols = data.shape\n",
    "#     cov_mat = np.zeros((cols, cols))\n",
    " \n",
    "#     for i in range(cols):\n",
    " \n",
    "#         for j in range(cols):\n",
    "#             # store the value in the matrix\n",
    "#             cov_mat[i][j] = calcCov(data[:, i], data[:, j])\n",
    " \n",
    "#     return cov_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f7662-693e-4ecc-ad40-ddeedba82e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mahalanobis_distance(p1,p2,X): #p1 is model, p2 is the test point\n",
    "#     # X is inverse cov matrix\n",
    "#     distance = np.dot(np.dot(np.subtract(p2,p1).T,np.array(X)),np.subtract(p2,p1))\n",
    "#     return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60612e00-9b32-4b29-a379-ff89b75bed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1cov = cov(X1)\n",
    "# X1cov = np.linalg.inv(X1cov)\n",
    "# distance = mahalanobis_distance(X1[0],X1[1],X1cov)\n",
    "# C1 = np.zeros((X1.shape[0],X1.shape[0]))\n",
    "\n",
    "# for i in range(X1.shape[0]):\n",
    "#     for j in range(X1.shape[0]):\n",
    "#         C1[i][j] = mahalanobis_distance(X1[i],X1[j],X1cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c926208-3ffd-457c-96f3-5eb98bd69919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a748d1f-ec99-46ea-8984-ca7171e3e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2cov = cov(X2) \n",
    "# C2 = np.zeros((X2.shape[0],X2.shape[0]))\n",
    "\n",
    "# for i in range(X2.shape[0]):\n",
    "#     for j in range(X2.shape[0]):\n",
    "#         C2[i][j] = mahalanobis_distance(X2[i],X2[j],X2cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680fc927-c660-442d-8253-38c0aa6b6508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaeb869-30e3-4e51-9302-52ba15f759b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up LMNN\n",
    "X1lmnn = metric_learn.LMNN(k=5, learn_rate=1e-6)\n",
    "\n",
    "# fit the data!\n",
    "X1_lmnn = X1lmnn.fit_transform(X1, y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322573d8-554f-45c1-a4c7-03dd86a4b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmnn_metric_X1  = X1lmnn.get_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e15f317-a0b0-4011-a445-c3e1fd4bfc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = np.zeros((X1.shape[0],X1.shape[0]))\n",
    "\n",
    "for i in range(X1.shape[0]):\n",
    "    for j in range(X1.shape[0]):\n",
    "        C1[i][j] = lmnn_metric_X1(X1[i],X1[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b53437d-471b-4dfa-b6e0-b2ba3f0ed60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up LMNN\n",
    "X2lmnn = metric_learn.LMNN(k=5, learn_rate=1e-6)\n",
    "\n",
    "# fit the data!\n",
    "X2_lmnn = X2lmnn.fit_transform(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ea72ab-9967-4913-bda6-b065792b2820",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmnn_metric_X2 = X2lmnn.get_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a2e0ca-68a4-4600-944a-f88281aa099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "C2 = np.zeros((X2.shape[0],X2.shape[0]))\n",
    "\n",
    "for i in range(X2.shape[0]):\n",
    "    for j in range(X2.shape[0]):\n",
    "        C2[i][j] = lmnn_metric_X2(X2[i],X2[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb5cc8a-7c70-482b-a59d-a416b0623260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0620ddd-59ef-44d2-9c79-f5cd369b6804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4da8b6a-e532-4136-a21e-07d3277e2392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf0ab9a-ff20-46c5-9221-020165bfe7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52156bca-daed-4a4f-a8b6-fffe821b1788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7b39d-85f9-442a-980d-d67ad29147be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe1e647-30bf-490b-afbb-29619135a364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a057928-076c-4ffa-a23e-c89292377c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dca6a9e-7b19-492e-945c-eab74ce9b98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f2189-bdd9-4549-9659-e707f335eb09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d0d21-fd4d-47be-874e-71b9024bc1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739af794-1f28-41c3-b349-a66bec273a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06aef33-f56b-4e1d-9ee3-c7a280079b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62add19-0747-4575-86f5-eafc1f9fdad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5cd0bc-068c-477a-b9c0-f06d09804e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333118a8-dccc-4704-95de-5579b8697ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b47d9-1220-4ce8-9f67-0387bc115d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4086a1-14fe-4c05-b689-4c78191b777a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119c3c7-90c0-46a2-b81c-005671867673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33aa9f9-3d37-4023-8239-b126d6a5e29f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c984d8-b157-4ca2-afc3-2cceb17f12ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aa7a04-a068-40dc-b4c2-0c24bb99a24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb71b9a-e353-42f2-8122-e4b8d92e715c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f24100c-6761-4dd3-98d4-e5aad8b435b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be6ff5-a84b-40fb-a67d-2940bcf3463c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ca1802-513b-4456-8e08-0baeb33346ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe9743b-0b61-4182-9be9-5329884839c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf4367a-abc1-4c25-97b8-d12f4c9ccf48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d958acad-127e-4545-9b38-0c6e18d8a295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc02b0a7-e47a-4cc1-9478-441f04ac95bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "import torch\n",
    "\n",
    "import ot\n",
    "from ot.gromov import gromov_wasserstein2\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "def min_weight_gw(C1, C2, a2, nb_iter_max=100, lr=1e-2):\n",
    "    \"\"\" solve min_a GW(C1,C2,a, a2) by gradient descent\"\"\"\n",
    "\n",
    "    # use pyTorch for our data\n",
    "    C1_torch = torch.tensor(C1)\n",
    "    C2_torch = torch.tensor(C2)\n",
    "\n",
    "    a0 = rng.rand(C1.shape[0])  # random_init\n",
    "    a0 /= a0.sum()  # on simplex\n",
    "    a1_torch = torch.tensor(a0).requires_grad_(True)\n",
    "    a2_torch = torch.tensor(a2)\n",
    "\n",
    "    loss_iter = []\n",
    "\n",
    "    for i in range(nb_iter_max):\n",
    "\n",
    "        loss = gromov_wasserstein2(C1_torch, C2_torch, a1_torch, a2_torch)\n",
    "\n",
    "        loss_iter.append(loss.clone().detach().cpu().numpy())\n",
    "        loss.backward()\n",
    "\n",
    "        #print(\"{:03d} | {}\".format(i, loss_iter[-1]))\n",
    "\n",
    "        # performs a step of projected gradient descent\n",
    "        with torch.no_grad():\n",
    "            grad = a1_torch.grad\n",
    "            a1_torch -= grad * lr   # step\n",
    "            a1_torch.grad.zero_()\n",
    "            a1_torch.data = ot.utils.proj_simplex(a1_torch)\n",
    "\n",
    "    a1 = a1_torch.clone().detach().cpu().numpy()\n",
    "\n",
    "    return a1, loss_iter\n",
    "\n",
    "\n",
    "a0_est, loss_iter0 = min_weight_gw(C1, C2, ot.unif(C1.shape[0]), nb_iter_max=10, lr=1e-2)\n",
    "\n",
    "\n",
    "pl.figure(2)\n",
    "pl.plot(loss_iter0)\n",
    "pl.title(\"Loss along iterations\")\n",
    "\n",
    "print(\"Estimated weights : \", a0_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7287dff-e7f9-4ef5-befb-c8618498c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "a0_est.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ad14da-3824-4ad9-a4f8-9b43244b76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_graph(x, C, color='C0', s=None):\n",
    "    for j in range(C.shape[0]):\n",
    "        for i in range(j):\n",
    "            if C[i, j] > 0:\n",
    "                pl.plot([x[i, 0], x[j, 0]], [x[i, 1], x[j, 1]], alpha=0.2, color='k')\n",
    "    pl.scatter(x[:, 0], x[:, 1], c=color, s=s, zorder=10, edgecolors='k', cmap='tab10', vmax=9)\n",
    "\n",
    "    \n",
    "T_unif = ot.gromov_wasserstein(C2, C1, ot.unif(C1.shape[0]), ot.unif(C2.shape[0]))\n",
    "label_unif = T_unif.argmax(1)\n",
    "\n",
    "T_est = ot.gromov_wasserstein(C2, C1, ot.unif(C1.shape[0]), a0_est)\n",
    "label_est = T_est.argmax(1)\n",
    "\n",
    "# get 2d position for nodes\n",
    "x1 = MDS(dissimilarity='precomputed', random_state=0).fit_transform(1 - C1)\n",
    "\n",
    "# pl.figure(3, (10, 5))\n",
    "# pl.clf()\n",
    "# pl.subplot(1, 2, 1)\n",
    "# plot_graph(x1, C1, color=label_unif)\n",
    "# pl.title(\"Graph clustering unif. weights\")\n",
    "# pl.axis(\"off\")\n",
    "# pl.subplot(1, 2, 2)\n",
    "# plot_graph(x1, C1, color=label_est)\n",
    "# pl.title(\"Graph clustering est. weights\")\n",
    "# pl.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102eba73-9e57-4108-b806-97823d418947",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_unif.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f78ca66-08db-4215-b4dc-483c3d6dda16",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_est.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d42685-10d3-4226-b60f-6f45b9eee876",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_unif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e890fc-6910-4cc1-98de-aee17721e3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6488325-1dcf-4d9b-aabf-c79fdf11fd08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe4fe74-0218-4d7c-9d50-3eadef0569a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_compession_gw(nb_nodes, C2, a2, nb_iter_max=100, lr=1e-2):\n",
    "    \"\"\" solve min_a GW(C1,C2,a, a2) by gradient descent\"\"\"\n",
    "\n",
    "    # use pyTorch for our data\n",
    "\n",
    "    C2_torch = torch.tensor(C2)\n",
    "    a2_torch = torch.tensor(a2)\n",
    "\n",
    "    a0 = rng.rand(nb_nodes)  # random_init\n",
    "    a0 /= a0.sum()  # on simplex\n",
    "    a1_torch = torch.tensor(a0).requires_grad_(True)\n",
    "    C0 = np.eye(nb_nodes)\n",
    "    C1_torch = torch.tensor(C0).requires_grad_(True)\n",
    "\n",
    "    loss_iter = []\n",
    "\n",
    "    for i in range(nb_iter_max):\n",
    "\n",
    "        loss = gromov_wasserstein2(C1_torch, C2_torch, a1_torch, a2_torch)\n",
    "\n",
    "        loss_iter.append(loss.clone().detach().cpu().numpy())\n",
    "        loss.backward()\n",
    "\n",
    "        #print(\"{:03d} | {}\".format(i, loss_iter[-1]))\n",
    "\n",
    "        # performs a step of projected gradient descent\n",
    "        with torch.no_grad():\n",
    "            grad = a1_torch.grad\n",
    "            a1_torch -= grad * lr   # step\n",
    "            a1_torch.grad.zero_()\n",
    "            a1_torch.data = ot.utils.proj_simplex(a1_torch)\n",
    "\n",
    "            grad = C1_torch.grad\n",
    "            C1_torch -= grad * lr   # step\n",
    "            C1_torch.grad.zero_()\n",
    "            C1_torch.data = torch.clamp(C1_torch, 0, 1)\n",
    "\n",
    "    a1 = a1_torch.clone().detach().cpu().numpy()\n",
    "    C1 = C1_torch.clone().detach().cpu().numpy()\n",
    "\n",
    "    return a1, C1, loss_iter\n",
    "\n",
    "\n",
    "# nb_nodes = C2.shape[0]\n",
    "# a0_est2, C0_est2, loss_iter2 = graph_compession_gw(nb_nodes, C2, ot.unif(C2.shape[0]),\n",
    "#                                                    nb_iter_max=300, lr=5e-2)\n",
    "\n",
    "# pl.figure(4)\n",
    "# pl.plot(loss_iter2)\n",
    "# pl.title(\"Loss along iterations\")\n",
    "\n",
    "\n",
    "# print(\"Estimated weights : \", a0_est2)\n",
    "\n",
    "# pl.figure(6, (10, 3.5))\n",
    "# pl.clf()\n",
    "# pl.imshow(C0_est2, vmin=0, vmax=1)\n",
    "# pl.title('Estimated C0 matrix')\n",
    "# pl.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0015d5-8eda-4d03-b7f2-d0a42c7f6914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a0_est2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e477f947-b472-48e1-b18c-5d090332fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C0_est2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a0b0f8-04aa-4d7d-a043-f68b4288b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval function\n",
    "\n",
    "import numpy as np\n",
    "import random, math, os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_auc_score, silhouette_samples\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def calc_frac_idx(x1_mat,x2_mat):\n",
    "    \"\"\"\n",
    "    Returns fraction closer than true match for each sample (as an array)\n",
    "    \"\"\"\n",
    "    fracs = []\n",
    "    x = []\n",
    "    nsamp = x1_mat.shape[0]\n",
    "    rank=0\n",
    "    for row_idx in range(nsamp):\n",
    "        euc_dist = np.sqrt(np.sum(np.square(np.subtract(x1_mat[row_idx,:], x2_mat)), axis=1))\n",
    "        true_nbr = euc_dist[row_idx]\n",
    "        sort_euc_dist = sorted(euc_dist)\n",
    "        rank =sort_euc_dist.index(true_nbr)\n",
    "        frac = float(rank)/(nsamp -1)\n",
    "\n",
    "        fracs.append(frac)\n",
    "        x.append(row_idx+1)\n",
    "\n",
    "    return fracs,x\n",
    "\n",
    "def calc_domainAveraged_FOSCTTM(x1_mat, x2_mat):\n",
    "    \"\"\"\n",
    "    Outputs average FOSCTTM measure (averaged over both domains)\n",
    "    Get the fraction matched for all data points in both directions\n",
    "    Averages the fractions in both directions for each data point\n",
    "    \"\"\"\n",
    "    \n",
    "    fracs1,xs = calc_frac_idx(x1_mat, x2_mat)\n",
    "    fracs2,xs = calc_frac_idx(x2_mat, x1_mat)\n",
    "    fracs = []\n",
    "    for i in range(len(fracs1)):\n",
    "        fracs.append((fracs1[i]+fracs2[i])/2)  \n",
    "    return fracs\n",
    "\n",
    "def calc_sil(x1_mat,x2_mat,x1_lab,x2_lab):\n",
    "    \"\"\"\n",
    "    Returns silhouette score for datasets with cell clusters\n",
    "    \"\"\"\n",
    "    sil = []\n",
    "    sil_d0 = []\n",
    "    sil_d3 = []\n",
    "    sil_d7 = []\n",
    "    sil_d11 = []\n",
    "    sil_npc = []\n",
    "\n",
    "    x = np.concatenate((x1_mat,x2_mat))\n",
    "    lab = np.concatenate((x1_lab,x2_lab))\n",
    "\n",
    "    sil_score = silhouette_samples(x,lab)\n",
    "\n",
    "    nsamp = x.shape[0]\n",
    "    for i in range(nsamp):\n",
    "        if(lab[i]==1):\n",
    "            sil_d0.append(sil_score[i])\n",
    "        elif(lab[i]==2):\n",
    "            sil_d3.append(sil_score[i])\n",
    "        elif(lab[i]==3):\n",
    "            sil_d7.append(sil_score[i])\n",
    "        elif(lab[i]==4):\n",
    "            sil_d11.append(sil_score[i])\n",
    "        elif(lab[i]==5):\n",
    "            sil_npc.append(sil_score[i])\n",
    "\n",
    "    avg = np.mean(sil_score)\n",
    "    d0 = sum(sil_d0)/len(sil_d0)\n",
    "    d3 = sum(sil_d3)/len(sil_d3)\n",
    "    d7 = sum(sil_d7)/len(sil_d7)\n",
    "    d11 = sum(sil_d11)/len(sil_d11)\n",
    "    npc = sum(sil_npc)/len(sil_npc)\n",
    "\n",
    "    return avg,d0,d3,d7,d11,npc\n",
    "\n",
    "def binarize_labels(label,x):\n",
    "    \"\"\"\n",
    "    Helper function for calc_auc\n",
    "    \"\"\"\n",
    "    bin_lab = np.array([1] * len(x))\n",
    "    idx = np.where(x == label)\n",
    "\n",
    "    bin_lab[idx] = 0\n",
    "    return bin_lab\n",
    "\n",
    "\n",
    "def calc_auc(x1_mat, x2_mat, x1_lab, x2_lab):\n",
    "    \"\"\"\n",
    "    calculate avg. ROC AUC scores for transformed data when there are >=2 number of clusters.\n",
    "    \"\"\"\n",
    "\n",
    "    nsamp = x1_mat.shape[0]\n",
    "\n",
    "    auc = []\n",
    "    auc_d0 = []\n",
    "    auc_d3 = []\n",
    "    auc_d7 = []\n",
    "    auc_d11 = []\n",
    "    auc_npc = []\n",
    "\n",
    "    for row_idx in range(nsamp):\n",
    "        euc_dist = np.sqrt(np.sum(np.square(np.subtract(x1_mat[row_idx,:], x2_mat)), axis=1))\n",
    "        y_scores = euc_dist\n",
    "        y_true = binarize_labels(x1_lab[row_idx],x2_lab)\n",
    "\n",
    "        auc_score = roc_auc_score(y_true, y_scores)\n",
    "        auc.append(auc_score)\n",
    "        \n",
    "        if(x1_lab[row_idx]==0):\n",
    "            auc_d0.append(auc_score)\n",
    "        elif(x1_lab[row_idx]==1):\n",
    "            auc_d3.append(auc_score)\n",
    "        elif(x1_lab[row_idx]==2):\n",
    "            auc_d7.append(auc_score)\n",
    "        elif(x1_lab[row_idx]==3):\n",
    "            auc_d11.append(auc_score)\n",
    "        elif(x1_lab[row_idx]==4):\n",
    "            auc_npc.append(auc_score)\n",
    "\n",
    "    avg = sum(auc)/len(auc)\n",
    "    d0 = sum(auc_d0)/len(auc_d0)\n",
    "    d3 = sum(auc_d3)/len(auc_d3)\n",
    "    d7 = sum(auc_d7)/len(auc_d7)\n",
    "    d11 = sum(auc_d11)/len(auc_d11)\n",
    "    npc = sum(auc_npc)/len(auc_npc)\n",
    "\n",
    "    return avg,d0,d3,d7,d11,npc\n",
    "\n",
    "def transfer_accuracy(domain1, domain2, type1, type2, n):\n",
    "    \"\"\"\n",
    "    Metric from UnionCom: \"Label Transfer Accuracy\"\n",
    "    \"\"\"\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    knn.fit(domain2, type2)\n",
    "    type1_predict = knn.predict(domain1)\n",
    "    np.savetxt(\"type1_predict.txt\", type1_predict)\n",
    "    count = 0\n",
    "    for label1, label2 in zip(type1_predict, type1):\n",
    "        if label1 == label2:\n",
    "            count += 1\n",
    "    return count / len(type1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe510e68-ff2f-48f5-bf04-ca9034dda586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# projection\n",
    "\n",
    "#Projecting the first domain onto the second domain\n",
    "y_aligned_from_normalized=X2\n",
    "weights_from_normalized=np.sum(T_unif,axis = 0)\n",
    "X_aligned_from_normalized=np.matmul(T_unif, X2) / weights_from_normalized[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e11cca-e184-411b-849c-96e6e6d1c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the average FOSCTTM measure implemented in evals.py for evaluation (metric used in the publication Demetci et al 2021)\n",
    "# This measure reports the fraction of samples closer to a sample than its true match (FOSCTTM), averaged over all samples. \n",
    "fracs_normalized=calc_domainAveraged_FOSCTTM(X_aligned_from_normalized, y_aligned_from_normalized)\n",
    "print(\"Average FOSCTTM score for this alignment with X onto Y is: \", np.mean(fracs_normalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379a8e9-270c-4c9b-bdcf-5f5af2e7d72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting sorted FOSCTTM to show the distributions of FOSCTTM across cells:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "legend_label=\"SCOT alignment FOSCTTM \\n average value: \"+str(np.mean(fracs_normalized)) #Put average FOSCTTM in the legend\n",
    "plt.plot(np.arange(len(fracs_normalized)), np.sort(fracs_normalized), \"r--\", label=legend_label)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Cells\")\n",
    "plt.ylabel(\"Sorted FOSCTTM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe01fcc-dc59-4b4f-a551-f2042260ffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Reduce the dimensionality of the aligned domains to two (2D) via PCA for the sake of visualization:\n",
    "pca=PCA(n_components=2)\n",
    "Xy_pca=pca.fit_transform(np.concatenate((X_aligned_from_normalized, y_aligned_from_normalized), axis=0))\n",
    "X_pca=Xy_pca[0: 1047,]\n",
    "y_pca=Xy_pca[1047:,]\n",
    "\n",
    "#Plot aligned domains, samples colored by domain identity:\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=\"k\", s=15, label=\"Chromatin Accessibility\")\n",
    "plt.scatter(y_pca[:,0], y_pca[:,1], c=\"r\", s=15, label=\"Gene Expression\")\n",
    "plt.legend()\n",
    "plt.title(\"Colored based on domains\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure\n",
    "#Plot aligned domains, samples colored by domain identity:\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=\"k\", s=15, label=\"Chromatin Accessibility\")\n",
    "plt.legend()\n",
    "plt.title(\"Colored based on domains\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure\n",
    "#Plot aligned domains, samples colored by domain identity:\n",
    "plt.scatter(y_pca[:,0], y_pca[:,1], c=\"r\", s=15, label=\"Gene Expression\")\n",
    "plt.legend()\n",
    "plt.title(\"Colored based on domains\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fee1f8-a90b-45fe-9037-c26a5cfb45e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot aligned domains, samples colored by cell types:\n",
    "cellTypes_atac=np.loadtxt(\"../data/SNAREseq_atac_types.txt\")\n",
    "cellTypes_rna=np.loadtxt(\"../data/SNAREseq_rna_types.txt\")\n",
    "\n",
    "colormap = plt.get_cmap('rainbow', 4) \n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=cellTypes_atac, s=15, cmap=colormap)\n",
    "plt.scatter(y_pca[:,0], y_pca[:,1], c=cellTypes_rna, s=15, cmap=colormap)\n",
    "# plt.colorbar()\n",
    "cbar=plt.colorbar()\n",
    "\n",
    "# approximately center the colors on the colorbar when adding cell type labels\n",
    "tick_locs = (np.arange(1,5)+0.75) *3/4 \n",
    "cbar.set_ticks(tick_locs)\n",
    "cbar.set_ticklabels([\"H1\", \"GM\", \"BJ\", \"K562\"]) #cell-type labels\n",
    "plt.title(\"Colored based on cell type identity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c64b74-e6eb-4b51-92a8-98bf8165e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "originalX_pca=pca.fit_transform(X1)\n",
    "originaly_pca=pca.fit_transform(X2)\n",
    "\n",
    "#Visualization of the global geometry\n",
    "fig, (ax1, ax2)= plt.subplots(1,2)\n",
    "ax1.scatter(originalX_pca[:,0], originalX_pca[:,1], c=\"k\", s=15)\n",
    "ax1.set_title(\"Chromatin Accessibiliy Domain \\n *before* Alignment\")\n",
    "ax2.scatter(originaly_pca[:,0], originaly_pca[:,1], c=\"r\", s=15)\n",
    "ax2.set_title(\"Gene Expression Domain \\n *before* Alignment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766bd02f-e994-4a8a-bd6d-b2536d1ef93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of the cell type clusters in original domains *before* alignment\n",
    "fig, (ax1, ax2)= plt.subplots(1,2)\n",
    "\n",
    "fig1= ax1.scatter(originalX_pca[:,0], originalX_pca[:,1], c=cellTypes_atac, s=15, cmap=colormap)\n",
    "ax1.set_title(\"Chromatin Accessibiliy \\n *before* Alignment\")\n",
    "\n",
    "fig2= ax2.scatter(originaly_pca[:,0], originaly_pca[:,1],  c=cellTypes_rna, s=15, cmap=colormap)\n",
    "ax2.set_title(\"Gene Expression Domain \\n *before* Alignment\")\n",
    "\n",
    "cbar=fig.colorbar(fig2)\n",
    "cbar.set_ticks(tick_locs)\n",
    "cbar.set_ticklabels([\"H1\", \"GM\", \"BJ\", \"K562\"]) #cell-type labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e35b46-9b65-4d4b-ae4b-aab06f27ecd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c3182f-dde0-4556-b49b-6ff76f444ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f97eae-c4ef-4d95-9bdf-6841210bb8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
